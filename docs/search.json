[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "Florida Palmetto Species Classifier\n\n\n\nR\n\n\nModeling\n\n\nQuarto\n\n\n\n\n\n\n\nZoe Zhou\n\n\nFeb 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipal Components Analysis (PCA) on Soil Characteristics\n\n\n\nR\n\n\nModeling\n\n\nQuarto\n\n\n\n\n\n\n\nZoe Zhou\n\n\nFeb 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of Urbanization on Biodiversity\n\n\n\nPython\n\n\nSpatial Analysis\n\n\n\nThis project analyzes changes in the Biodiversity Intactness Index (BII) in Phoenix, Arizona (Maricopa County) between 2017 and 2020. The analysis aims to understand the…\n\n\n\nZoe Zhou\n\n\nFeb 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Wildfire Impact\n\n\n\nPython\n\n\nRemote Sensing\n\n\n\nDiscover how data from the Thomas Fire sheds light on wildfire impacts, from air quality degradation to environmental recovery, and its relevance to Los Angeles’ current…\n\n\n\nZoe Zhou\n\n\nJan 24, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zoe Zhou",
    "section": "",
    "text": "Welcome! Join me in navigating the world, one dataset at a time.\n\nEnter here"
  },
  {
    "objectID": "index.html#aspiring-environmental-data-scientist",
    "href": "index.html#aspiring-environmental-data-scientist",
    "title": "Zoe Zhou",
    "section": "",
    "text": "Welcome! Join me in navigating the world, one dataset at a time.\n\nEnter here"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html",
    "href": "posts/2025-02-17-PCA-soil/index.html",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "",
    "text": "Cattle on Namibia Rangeland. Photo by Tim Brunauer on behalf of Deutsche Gesellschaft für Internationale Zusammenarbeit (GIZ)"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#about",
    "href": "posts/2025-02-17-PCA-soil/index.html#about",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "About",
    "text": "About\nPrincipal Component Analysis (PCA) is an ordination method that allows us to extract as much information as possible from multivariate data by reducing it to a simplified number of dimensions. In this study, we will use PCA to eliminates multicollinearity, identify key variables and visualize interactions in soil characteristics that may influence plant trait responses to livestock grazing. By reducing the complexity of the dataset, PCA will help uncover patterns and relationships that are critical for understanding the ecological dynamics of grazing systems."
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#data-summary",
    "href": "posts/2025-02-17-PCA-soil/index.html#data-summary",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Data Summary",
    "text": "Data Summary\nSoil Environmental Data: The data used in this study is derived from a study on the effects of grazing on soil properties. (Wesuls et al., 2012) The dataset includes a variety of environmental variables grouped into categories such as grazing parameters, soil chemical and physical properties, soil surface characteristics, and topographical parameters. Below is a summary of the environmental variables used in the analysis:\n\n\n\n\n\n\n\n\nCategory\nVariables\nDescription\n\n\n\n\nGrazing parameters\nlogDist\nLogarithm of distance from watering point (m)\n\n\n\nGrazInt\nGrazing intensity (unitless)\n\n\nSoil chemical parameters\npH\npH value (measured in CaCO₃, unitless)\n\n\n\nConductivity\nElectrical conductivity (µS/cm)\n\n\n\nCl\nChloride concentration (ppm)\n\n\n\nNO2\nNitrite concentration (ppm)\n\n\n\nNO3\nNitrate concentration (ppm)\n\n\n\nPO4\nPhosphate concentration (ppm)\n\n\n\nSO4\nSulphate concentration (ppm)\n\n\n\nNa\nSodium concentration (ppm)\n\n\n\nNH4\nAmmonium concentration (ppm)\n\n\n\nK\nPotassium concentration (ppm)\n\n\n\nMg\nMagnesium concentration (ppm)\n\n\n\nCa\nCalcium concentration (ppm)\n\n\nSoil physical parameters\nSkeleton\nSkeleton fraction of the soil (% of particles &gt;0.2 cm)\n\n\n\nSoil depth\nSoil depth (cm)\n\n\nSoil surface parameters\nFine\nCover of fine material &lt;0.2 cm (%)\n\n\n\nGravel\nCover of gravel 0.2–2.0 cm (%)\n\n\n\nStones\nCover of stones &gt;2 cm (%)\n\n\n\nBlocks\nCover of blocks &gt;60 cm (%)\n\n\n\nWood\nCover of dead wood (%)\n\n\n\nLitter\nCover of litter (%)\n\n\n\nDung\nCover of dung (%)\n\n\n\nBiocrust\nCover of biological soil crust (%)\n\n\nTopographical parameters\nInclination\nInclination (% slope)\n\n\n\nCitation: Wesuls, D., Oldeland, J., and Dray, S. (2012). Disentangling plant trait responses to livestock grazing from spatio-temporal variation: the partial RLQ approach. Journal of Vegetation Science, 23: 98-113. https://doi.org/10.1111/j.1654-1103.2011.01342.x"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#analysis-outline",
    "href": "posts/2025-02-17-PCA-soil/index.html#analysis-outline",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Analysis Outline",
    "text": "Analysis Outline\n\nPreliminary data exploration\nData Wrangling\nRun PCA function\nPrincipal Components\nScree Plots\nPCA Biplot\nDiscussion"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#set-up",
    "href": "posts/2025-02-17-PCA-soil/index.html#set-up",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Set Up",
    "text": "Set Up\nWe will use the following libraries and set-up through this analysis\n\n\nCode\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(ggfortify)\nlibrary(kableExtra)\nlibrary(skimr)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#preliminary-data-exploration",
    "href": "posts/2025-02-17-PCA-soil/index.html#preliminary-data-exploration",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Preliminary Data Exploration",
    "text": "Preliminary Data Exploration\nFrom the data summary, we observed several challenges in the distribution figures. Many variables exhibited skewed distributions, particularly chemical concentration variables, which required transformations to normalize their ranges. Additionally, some variables, such as the Blocks column, had a high proportion of missing or zero values, making them less informative for analysis.\n\n\nClick to expand table\n\n\n\nCode\n# Load data  \nsoil &lt;- read.csv(\"data/grazing_env.csv\")\n#head(soil)\n#summary(soil)\n#glimpse(soil)\nskim(soil)\n\n\n\nData summary\n\n\nName\nsoil\n\n\nNumber of rows\n378\n\n\nNumber of columns\n25\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n25\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nInclination\n0\n1\n0.14\n0.37\n0.00\n0.00\n0.00\n0.00\n3.00\n▇▁▁▁▁\n\n\nGrazInt\n0\n1\n0.05\n0.03\n0.01\n0.03\n0.04\n0.06\n0.21\n▇▃▁▁▁\n\n\nlogDist\n0\n1\n5.39\n1.23\n1.61\n4.39\n5.63\n6.44\n7.25\n▁▂▅▆▇\n\n\npH\n0\n1\n5.71\n0.98\n4.00\n4.84\n5.50\n6.61\n7.74\n▆▇▃▆▃\n\n\nConductivity\n0\n1\n56.56\n72.78\n6.20\n15.62\n28.15\n69.95\n633.00\n▇▁▁▁▁\n\n\nSkeleton\n0\n1\n16.15\n16.97\n0.47\n3.80\n9.82\n22.09\n69.55\n▇▂▁▁▁\n\n\nWood\n0\n1\n0.38\n0.89\n0.00\n0.10\n0.10\n0.50\n15.00\n▇▁▁▁▁\n\n\nLitter\n0\n1\n10.77\n13.57\n0.00\n1.00\n3.00\n20.00\n60.00\n▇▁▂▁▁\n\n\nDung\n0\n1\n0.72\n1.44\n0.00\n0.10\n0.10\n0.50\n15.00\n▇▁▁▁▁\n\n\nBiocrust\n0\n1\n0.95\n3.36\n0.00\n0.00\n0.00\n0.10\n40.00\n▇▁▁▁▁\n\n\nFine\n0\n1\n67.69\n17.21\n0.00\n56.00\n70.00\n80.00\n99.00\n▁▁▅▇▆\n\n\nGravel\n0\n1\n17.04\n14.10\n0.00\n5.00\n15.00\n25.00\n70.00\n▇▆▂▁▁\n\n\nStones\n0\n1\n2.90\n4.52\n0.00\n0.00\n2.00\n3.00\n38.00\n▇▁▁▁▁\n\n\nBlocks\n0\n1\n0.04\n0.33\n0.00\n0.00\n0.00\n0.00\n5.00\n▇▁▁▁▁\n\n\nSoildepth\n0\n1\n32.80\n19.45\n0.00\n15.00\n27.88\n56.00\n60.00\n▅▆▅▂▇\n\n\nCl\n0\n1\n1.19\n0.93\n0.00\n0.63\n0.95\n1.51\n7.55\n▇▂▁▁▁\n\n\nNO2\n0\n1\n0.00\n0.02\n0.00\n0.00\n0.00\n0.00\n0.30\n▇▁▁▁▁\n\n\nNO3\n0\n1\n0.56\n1.32\n0.00\n0.06\n0.19\n0.57\n18.74\n▇▁▁▁▁\n\n\nPO4\n0\n1\n0.09\n0.16\n0.00\n0.00\n0.01\n0.13\n1.82\n▇▁▁▁▁\n\n\nSO4\n0\n1\n1.20\n0.90\n0.00\n0.61\n1.08\n1.56\n4.81\n▇▇▂▁▁\n\n\nNa\n0\n1\n2.06\n2.23\n0.05\n0.57\n1.12\n3.40\n10.53\n▇▃▁▁▁\n\n\nNH4\n0\n1\n0.11\n0.31\n0.00\n0.00\n0.00\n0.00\n1.40\n▇▁▁▁▁\n\n\nK\n0\n1\n1.11\n1.39\n0.02\n0.33\n0.48\n1.33\n6.17\n▇▁▂▁▁\n\n\nMg\n0\n1\n2.19\n1.95\n0.00\n0.53\n1.56\n3.40\n10.98\n▇▅▁▁▁\n\n\nCa\n0\n1\n2.74\n2.14\n0.00\n1.18\n2.02\n3.96\n10.05\n▇▅▂▂▁\n\n\n\n\n\n\nFigure 1 is a correlation heatmap that shows the pairwise correlations between variables in the dataset. The color scale on the right indicates the strength and direction of the correlations, ranging from -1.0 (blue) for strong negative correlations to 1.0 (brown) for strong positive correlations. For example, logDist is negatively correlated with Grazint, pH, Conductivity and Dung. Solidepth is negatively correlated with pH, Skeleton and Conductivity (blue), while positively correlated with Fine (brown). Highly correlated variables such as Ca, Na, K and Mg may indicate redundancy.\n\n\nCode\n# Create correlation heatmap\n# Select numeric columns for correlation analysis\nnumeric_features &lt;- soil[sapply(soil, is.numeric)]\n\n# Compute the correlation matrix\ncor_matrix &lt;- cor(numeric_features, use = \"complete.obs\")\n\n# Create df\ncor_df &lt;- as.data.frame(as.table(cor_matrix))\n\n# Create the heatmap\nggplot(cor_df, aes(Var1, Var2, fill = Freq)) +\n  geom_tile(color = \"white\") +  # Add gridlines\n  scale_fill_gradient2(low = \"lightblue\", high = \"#964B00\", mid = \"white\", midpoint = 0, \n                       limit = c(-1, 1), space = \"Lab\", name = \"Correlation\") +\n  labs(title = \"Correlation Heatmap of Soil Data\", x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\nFigure 1: Pairwise Correlation Heatmap of Soil Data\n\n\n\n\nManually identifying redundant variables from the heatmap can be tedious, which necessitate a principal component analysis. Before we start, let’s exam for NA values and select only numeric variables.\nPCA requires continuous numeric data with no NAs. So we must drop categorical and character data, and exclude any rows with NAs. We should also rescale so all numeric variables have a mean 0 and sd 1."
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#data-wrangling",
    "href": "posts/2025-02-17-PCA-soil/index.html#data-wrangling",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nFor variables with many zero values, particularly the Blocks column (97% blank), we opted to filter it out entirely. For chemical concentration variables, we applied a log transformation to reduce skew and compresses the range of values.\n\n\nClick to expand plots\n\n\n\nCode\n# select variables to transform\nchem_vars &lt;- c('Cl', \"NO2\", \"NO3\", \"PO4\", \"SO4\", \"Na\", \"NH4\", \"K\", \"Mg\", \"Ca\")\n\n# Apply log transformation\nsoil_log &lt;- soil %&gt;% \n  drop_na() %&gt;% \n  select(-Blocks) %&gt;% \n  mutate(across(all_of(chem_vars), ~log(. +1))) #%&gt;% \n  #mutate(GrazInt = factor(GrazInt, levels = c('Low', 'Medium','High', 'Very High')))\n\n# Check results\n#skim(soil_log)\n\n# Visualize results\nsoil_log_long &lt;- soil_log %&gt;% \n  pivot_longer(names_to = 'name', values_to = 'value', where(is.numeric)) \n\nggplot(soil_log_long, aes(x=value))+\n  geom_histogram()+\n  facet_wrap(~name, scales=\"free_x\")+\n  theme_minimal()\n\n\n\n\n\nFigure 2. Histograms of Variables Distribution"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#principal-component-analysis",
    "href": "posts/2025-02-17-PCA-soil/index.html#principal-component-analysis",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\n\n# Run PCA function\nsoil_pca &lt;- soil_log %&gt;% \n  select(where(is.numeric))%&gt;% \n  prcomp(center = TRUE, scale = TRUE)\n\n\n\nClick to expand summary results\n\n\n\nCode\n# Check results\nsummary(soil_pca)\n\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.0770 1.9051 1.5629 1.26768 1.21341 1.12259 1.05198\nProportion of Variance 0.1797 0.1512 0.1018 0.06696 0.06135 0.05251 0.04611\nCumulative Proportion  0.1797 0.3310 0.4328 0.49971 0.56106 0.61357 0.65968\n                           PC8     PC9    PC10    PC11    PC12    PC13    PC14\nStandard deviation     0.99704 0.94626 0.93328 0.81894 0.77381 0.76795 0.72014\nProportion of Variance 0.04142 0.03731 0.03629 0.02794 0.02495 0.02457 0.02161\nCumulative Proportion  0.70110 0.73841 0.77470 0.80265 0.82760 0.85217 0.87378\n                          PC15    PC16    PC17    PC18    PC19    PC20    PC21\nStandard deviation     0.70379 0.67570 0.59953 0.57469 0.56590 0.49866 0.48562\nProportion of Variance 0.02064 0.01902 0.01498 0.01376 0.01334 0.01036 0.00983\nCumulative Proportion  0.89442 0.91344 0.92842 0.94218 0.95552 0.96588 0.97571\n                          PC22    PC23    PC24\nStandard deviation     0.45498 0.44855 0.41810\nProportion of Variance 0.00863 0.00838 0.00728\nCumulative Proportion  0.98433 0.99272 1.00000\n\n\n\nThe loading (eigenvalues) of variables for 24 principal components is listed in table below.\n\n\nClick to expand table\n\n\n\nCode\nkable(soil_pca$rotation)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\nPC11\nPC12\nPC13\nPC14\nPC15\nPC16\nPC17\nPC18\nPC19\nPC20\nPC21\nPC22\nPC23\nPC24\n\n\n\n\nInclination\n0.2539393\n0.0650623\n0.2297164\n0.0580529\n0.0476872\n0.3963533\n-0.0449732\n-0.0515420\n-0.1964872\n0.0607843\n-0.4447328\n0.2533805\n-0.2782397\n0.1914872\n-0.1345121\n-0.0027120\n0.3931800\n-0.1207966\n-0.1179230\n-0.0730326\n0.1209062\n0.0247223\n-0.2185124\n-0.1523718\n\n\nGrazInt\n0.0198537\n0.2639080\n0.0845635\n-0.0248342\n-0.0579691\n0.4852557\n-0.3343718\n-0.0983452\n-0.3454373\n0.0412619\n-0.0155562\n-0.2148365\n0.3416707\n0.1121799\n0.2005560\n0.0286634\n-0.2009362\n0.1422254\n0.1215824\n0.1278545\n-0.3194311\n0.1604583\n0.0457422\n0.0497922\n\n\nlogDist\n0.0578106\n-0.3565990\n0.1763430\n0.2271823\n-0.1947831\n0.0591965\n0.0980750\n0.1479102\n0.0953776\n-0.2135787\n-0.0916105\n0.1475339\n-0.3661647\n-0.0083419\n-0.0337423\n0.0158058\n-0.0536997\n0.1966714\n0.3221000\n0.2277691\n-0.4264260\n0.2515008\n0.2240570\n0.0309153\n\n\npH\n0.0159855\n0.3799065\n0.1383138\n-0.1710469\n-0.1037849\n-0.0447218\n0.2331377\n0.1407851\n0.0120061\n0.1572887\n0.3274969\n0.1251140\n0.1154500\n-0.0606484\n-0.1342897\n0.1513944\n0.5023992\n0.1922263\n-0.0651812\n-0.1388447\n-0.1718654\n0.2772770\n0.3009512\n-0.0667539\n\n\nConductivity\n-0.0804869\n0.4215503\n0.0192748\n-0.0569194\n0.1430074\n-0.1488532\n-0.0034214\n0.0890602\n0.0051359\n-0.0648229\n-0.0544584\n-0.1943055\n-0.3158206\n-0.0237637\n0.1143789\n0.2285838\n0.2296048\n0.1381356\n0.2556716\n0.4356479\n-0.0241378\n-0.3243819\n-0.2276640\n0.2578194\n\n\nSkeleton\n0.3740760\n0.0955476\n0.2222969\n0.0673576\n0.1451579\n0.1122915\n-0.0064025\n-0.0476296\n0.0018446\n-0.0517589\n0.0360828\n0.0953704\n-0.0069136\n-0.2332236\n0.0774118\n-0.0289380\n-0.0691977\n-0.2898124\n0.1104439\n-0.0864533\n0.2178310\n-0.1189558\n0.4797966\n0.5351514\n\n\nWood\n-0.0014977\n-0.0762013\n0.1177754\n0.0870432\n-0.1615695\n-0.4277991\n-0.3305480\n-0.1984217\n-0.6718946\n-0.1478084\n0.2330092\n0.1829620\n-0.1047250\n-0.1037805\n-0.1129499\n-0.0299904\n0.0813919\n-0.0015864\n-0.0513372\n0.0553450\n0.0138313\n-0.0662852\n0.0203841\n-0.0348499\n\n\nLitter\n-0.3366835\n-0.0244869\n0.1551774\n0.0743487\n-0.2582520\n0.0012811\n0.0482718\n0.0599108\n-0.0472552\n0.0058470\n-0.3961124\n-0.1217574\n0.1899654\n0.0047011\n-0.4294992\n0.2030788\n-0.0803051\n0.2042751\n-0.2964977\n0.1946763\n0.2399902\n-0.0373025\n0.2350417\n0.2445129\n\n\nDung\n-0.0932240\n0.2359014\n-0.1921818\n-0.2905806\n0.2155088\n-0.2237510\n-0.0512624\n-0.0963766\n-0.0203824\n0.2973056\n-0.3586543\n0.5060489\n-0.0728913\n-0.1090018\n-0.0738766\n0.0246898\n-0.3244309\n-0.0595670\n0.0150675\n0.0647375\n-0.2566416\n0.1465322\n0.0825262\n0.0413395\n\n\nBiocrust\n-0.0601542\n0.0081315\n0.2725246\n0.2167519\n-0.2491879\n-0.1476091\n0.2242942\n0.0434494\n-0.1524751\n0.6852049\n-0.0206843\n-0.1890456\n-0.2158228\n0.0080686\n0.3306872\n-0.1117271\n-0.1388469\n-0.0496236\n-0.0207427\n-0.0502446\n0.0584419\n0.0783582\n-0.0642877\n0.0565628\n\n\nFine\n-0.3331280\n0.0769206\n-0.1968402\n-0.1370929\n-0.2137517\n0.2533994\n0.0767520\n0.0013240\n-0.0950304\n-0.1240232\n0.1500182\n0.1811970\n-0.1302849\n-0.1366587\n0.0847356\n-0.1021856\n-0.0002402\n-0.1463968\n0.2352979\n0.1782701\n0.4837707\n0.4581900\n-0.1174352\n0.1020399\n\n\nGravel\n0.2848551\n-0.1133042\n-0.0472434\n0.0980092\n0.4410881\n-0.2413856\n-0.1924158\n-0.0401444\n0.0374486\n0.1072176\n-0.0801840\n-0.2234664\n0.0455110\n0.0341883\n-0.0175163\n-0.1241602\n0.1160451\n0.3289112\n-0.0514915\n0.2005419\n0.2496451\n0.5316026\n0.0021983\n0.0710435\n\n\nStones\n0.2450656\n0.2144571\n0.3165837\n0.0365426\n-0.0468223\n0.0734916\n0.0475801\n0.0263857\n0.1337868\n-0.1585352\n0.1677852\n0.2499540\n-0.0720814\n-0.2404235\n0.1126783\n0.1757577\n-0.4277106\n0.3925879\n-0.2567525\n0.0533731\n0.2138729\n-0.0186729\n-0.2071613\n-0.2162201\n\n\nSoildepth\n-0.1125974\n-0.2178989\n-0.3697970\n-0.0687573\n0.1405507\n0.2928878\n-0.0229655\n-0.0458967\n-0.1389780\n0.1632949\n0.1937010\n0.1362654\n-0.3336418\n0.1611334\n0.2048896\n0.0629920\n0.0444800\n0.4057586\n-0.2906494\n-0.0392950\n0.0601039\n-0.2226013\n0.2750225\n0.1531502\n\n\nCl\n-0.1722264\n0.0935049\n0.0200394\n0.5297524\n0.2227122\n-0.0306259\n-0.0216152\n-0.0974893\n0.0914743\n0.0546746\n0.2249745\n0.2384655\n0.0898750\n0.4456517\n0.0024589\n0.4409059\n-0.0753521\n-0.2424615\n0.0377073\n0.1160407\n0.0702210\n0.0875443\n0.0635886\n-0.0642748\n\n\nNO2\n0.0267892\n-0.0812970\n-0.0309618\n-0.0067018\n0.0641105\n0.0100664\n-0.3276688\n0.8965307\n-0.1141700\n0.1270301\n0.0411850\n0.1222369\n0.0732664\n-0.0101842\n-0.0204803\n0.0520621\n-0.0471019\n-0.0796327\n0.0366642\n-0.0184513\n0.0854992\n-0.0537895\n-0.0309727\n-0.0224835\n\n\nNO3\n-0.2576116\n0.2884030\n0.0436264\n0.0541128\n0.1050382\n-0.0820376\n-0.2141835\n0.0510311\n0.0013296\n-0.2431456\n-0.1749648\n-0.2990270\n-0.3957910\n0.0219281\n0.0548266\n0.0618273\n-0.1352112\n0.0273654\n0.0621720\n-0.5145279\n0.0869837\n0.1402002\n0.2751608\n-0.2137856\n\n\nPO4\n-0.2808329\n0.1423000\n0.0987316\n0.2824848\n0.0353945\n-0.1128036\n-0.0144136\n0.0789924\n0.0906207\n-0.2171343\n-0.2108518\n0.3049105\n0.2542037\n0.0202246\n0.4551069\n-0.4711552\n0.2224280\n0.1543632\n-0.1259659\n0.0184160\n-0.0198214\n-0.0866207\n0.0686905\n0.0431674\n\n\nSO4\n-0.1228572\n0.1941863\n-0.1106035\n0.3734078\n0.3147183\n0.2071764\n0.2263396\n0.1063871\n-0.1636480\n-0.0214117\n0.1780244\n-0.1261630\n-0.1472230\n-0.2940371\n-0.3654662\n-0.3338114\n-0.1058572\n-0.1171068\n-0.2563159\n0.0880423\n-0.2321107\n0.0262218\n-0.0973960\n0.0248773\n\n\nNa\n0.1868670\n0.1289495\n-0.3734227\n0.3476698\n-0.2322611\n-0.0606111\n0.0440100\n0.0086923\n-0.0505677\n-0.0130020\n-0.0917187\n0.1120927\n0.0933374\n-0.0090546\n-0.1151274\n0.1035680\n-0.0080006\n0.2801555\n0.1943636\n-0.4525322\n-0.0302682\n0.0464908\n-0.3170906\n0.3837800\n\n\nNH4\n-0.1225743\n0.0545190\n0.0710605\n0.1265304\n-0.1869802\n0.1134638\n-0.6077156\n-0.1809255\n0.4724127\n0.3005274\n0.1731947\n0.0700292\n-0.1240187\n-0.1682535\n-0.2375240\n-0.1850958\n0.1152072\n0.0465455\n0.0554706\n0.0193226\n-0.0083214\n-0.0898006\n-0.0255858\n0.0248830\n\n\nK\n0.2447722\n0.1790877\n-0.3574563\n0.2291239\n-0.1539171\n0.0152788\n0.0975051\n-0.0122431\n-0.0748274\n0.1302239\n-0.1341643\n-0.0202668\n0.0780070\n-0.0946630\n-0.0680839\n-0.1111737\n-0.0099697\n0.0915677\n0.2965476\n0.2224671\n0.2271014\n-0.2281904\n0.3558868\n-0.4949076\n\n\nMg\n0.2182573\n0.1008650\n-0.3390312\n0.1122050\n-0.3310605\n-0.0684199\n-0.1604597\n0.0427000\n0.1217436\n-0.1172659\n-0.1060288\n-0.1159445\n-0.1158754\n-0.1532328\n0.2728809\n0.2126120\n0.1002475\n-0.3122382\n-0.5064922\n0.1850132\n-0.1546163\n0.1937166\n0.0539820\n0.0178529\n\n\nCa\n0.2153951\n0.2740671\n-0.0223808\n-0.1535181\n-0.2309902\n-0.1172696\n0.0160856\n0.0948907\n0.0725268\n-0.1089284\n0.1430596\n0.0002931\n-0.1553977\n0.6471494\n-0.1906402\n-0.4123894\n-0.2142564\n-0.0201166\n-0.1122681\n0.1015696\n0.0248113\n0.0083516\n0.0520306\n0.1359311"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#principal-components-results",
    "href": "posts/2025-02-17-PCA-soil/index.html#principal-components-results",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Principal Components Results",
    "text": "Principal Components Results\nInterpretation: PC1 explains 17.97% of the variance, and PC2 explains 15.12%, together accounting for approximately 33.1% of the total variance.\nIn PC1, Skeleton (0.37), Gravel (0.28), Inclination (0.25), Stones (0.25), and K (0.24) are the strongest positive contributors. Litter (-0.34), Fine (-0.33), PO4 (-0.28), and NO3 (-0.26) are the strongest negative contributors.\nIn PC2, Conductivity, pH, Ca, NO3, and Dung are the strongest positive contributors, while logDist and Soildepth are the strongest negative contributors.\nPC3’s Key Contributors includes Stones, Biocrust, Skeleton, and Inclination as the strongest positive contributors. Soildepth, Na, K, and Mg are the strongest negative contributors."
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#scree-plots",
    "href": "posts/2025-02-17-PCA-soil/index.html#scree-plots",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Scree Plots",
    "text": "Scree Plots\nA scree plot is created for visualizating PC contributions (Figure 3).\n\n\nCode\n# screeplot\n#screeplot(soil_pca, type='lines')\n\n# create df\npc_names &lt;- colnames(soil_pca$rotation)\nsd_vec &lt;- soil_pca$sdev\nvar_vec &lt;- sd_vec^2\n\npct_expl_df &lt;- data.frame(v=var_vec,\n                          pct_v = var_vec/sum(var_vec),\n                          pc = pc_names)\npct_expl_df$pc &lt;- factor(pct_expl_df$pc, levels = pc_names)\n# plot \nggplot(pct_expl_df, aes(x = pc, y = pct_v)) +\n  geom_col(fill = \"lightblue\",alpha = 0.7) +\n  labs(title = \"Scree Plot\", x = 'Principal component', y = 'Variance explained')+\n  scale_y_continuous(labels = scales::percent)+\n  theme_minimal()+\n  theme(panel.grid = element_blank(),\n        axis.text.x = element_text(angle = 45, hjust = 1))+\n  geom_text(aes(label = scales::percent(pct_v, accuracy = 0.1)), \n            angle = 25, hjust = -0.25, size = 3) \n\n\n\n\n\nFigure 3. Scree-plot explaining variance captured by each component"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#biplot",
    "href": "posts/2025-02-17-PCA-soil/index.html#biplot",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Biplot",
    "text": "Biplot\nA biplot for PCA showing 1. The loading of variables for the first two principal components(brown arrows), and 2. The score of each observations based on the first two principal components is created for futher explaination (Figure 4).\nThe length of the arrows indicates the strength of the contribution of each variable to the principal components. Longer arrows represent stronger contributions. The direction of the arrows shows how variables are correlated with each other and with the principal components.The points are colored based on the “Skeleton” variable, with darker points indicating higher skeleton content.\n\n\nCode\nautoplot(soil_pca, \n         data = soil_log,\n         loadings=TRUE,\n         colour = 'Skeleton',\n         loadings.label=TRUE,\n         loadings.colour = \"#964B00\",\n           loadings.label.colour = \"#964B00\",\n           loadings.label.vjust = -0.5\n        ) +\n  scale_color_gradient(low=\"lightblue\", high='darkblue') +\n  theme_minimal()\n\n\n\n\n\nFigure 4. PCA Biplot: Soil Environmental Variables"
  },
  {
    "objectID": "posts/2025-02-17-PCA-soil/index.html#discussion",
    "href": "posts/2025-02-17-PCA-soil/index.html#discussion",
    "title": "Principal Components Analysis (PCA) on Soil Characteristics",
    "section": "Discussion",
    "text": "Discussion\nThis biplot provides a clear visualization of how soil properties and environmental factors vary and interact across the dataset. To get ~80% of variance explained, we must include 11 principle components.\nSkeleton is strongly positively correlated with PC1, indicating that areas with higher skeleton content have higher PC1 scores.\nVariables such as Skeleton, Gravel, Inclination, Ca, and Stones have arrows pointing in the same direction along PC1. Variables like Conductivity, pH, GrazInt, and Dung are more aligned with PC2. This suggests that PC2 captures a gradient related to soil chemistry and grazing intensity."
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html",
    "href": "posts/2025-02-03-urban-biodiversity/index.html",
    "title": "Impact of Urbanization on Biodiversity",
    "section": "",
    "text": "Link to github repo\nCourse Website: EDS 220"
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html#about",
    "href": "posts/2025-02-03-urban-biodiversity/index.html#about",
    "title": "Impact of Urbanization on Biodiversity",
    "section": "About",
    "text": "About\nPurpose: This project analyzes changes in the Biodiversity Intactness Index (BII) in Phoenix, Arizona (Maricopa County) between 2017 and 2020. The analysis aims to understand the impact of urban expansion on local biodiversity, as Phoenix has experienced significant urban development in recent decades.\nHighlights:\n\nData Exploration: Accessing and extracting geospatial data through the pystac_client API,focusing on specific collections and spatial extents. Implementing raster data processing using rioxarray.\nTemporal BII Analysis: Analyzing changes in the Biodiversity Intactness Index (BII) across Phoenix from 2017 to 2020, with particular emphasis on areas maintaining high biodiversity values (BII ≥ 0.75). Quantifying percentage changes to measure the impact of urban development on local ecosystems.\nSpatial Visualization: Developing comprehensive visualizations using multiple data layers to illustrate biodiversity changes. Combining vector and raster datasets to create informative maps that highlight areas of significant BII loss.\n\nAbout the data:\nThis study utilizes two primary datasets to analyze biodiversity changes in Phoenix. The Biodiversity Intactness Index (BII) data is sourced from Microsoft Planetary Computer’s STAC catalog’s io-biodiversity collection, specifically focusing on temporal changes between 2017 and 2020. The analysis area is defined by a bounding box with coordinates [-112.826843, 32.974108, -111.184387, 33.863574] encompassing the Phoenix metropolitan region. The study area boundaries are defined using the Phoenix subdivision shapefile, obtained from the 2020 TIGER/Line® Shapefiles published by the US Census Bureau, which provides detailed county subdivision boundaries for Arizona.\nSource:\nMicrosoft Open Source, Matt McFarland, Rob Emanuele, Dan Morris, & Tom Augspurger. (2022). microsoft/PlanetaryComputer: October 2022 (2022.10.28). Zenodo. https://doi.org/10.5281/zenodo.7261897 Accessed: 2024-12-02\n2020 TIGER/Line Shapefiles (machinereadable data files) / prepared by the U.S. Census Bureau, 2020 https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2020&layergroup=County+Subdivisions Accessed: 2024-12-02\n\nSet Up\nWe will use the following libraries and set-up through this analysis\n\n# Import libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt # To plot the final figure\nimport matplotlib.pyplot as mlines # To add legend to final figure\nimport geopandas as gpd # To work with shapefiles\nimport rioxarray as rioxr # To work with rasters\nimport contextily as ctx # To add a basemap\n\nfrom pystac_client import Client # To access STAC catalogs\n\nimport planetary_computer # To sign items from the MPC STAC catalog\n\nfrom IPython.display import Image # To nicely display images\n\n# Set option to display all columns\npd.set_option('display.max_columns', None)\n\n\n\nData Exploration\n\nBefore retriveing any data, update .gitignore with the entire data directory for best version control efficiency.\nDownload and import TIGER county subdivisons shapefile for Arizona in 2020.\nAdd a base map from the contextily package\n\n\n# Load boundary data\narizona = gpd.read_file(os.path.join('./data/','tl_2020_04_cousub.shp'))\narizona.head()\n\n# Filter for Phoenix\nphoenix = arizona[arizona['NAME'] == 'Phoenix'] \nphoenix.head()\n\n# Get general information about data\nphoenix.plot()\nphoenix.crs\n\n&lt;Geographic 2D CRS: EPSG:4269&gt;\nName: NAD83\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: North America - onshore and offshore: Canada - Alberta; British Columbia; Manitoba; New Brunswick; Newfoundland and Labrador; Northwest Territories; Nova Scotia; Nunavut; Ontario; Prince Edward Island; Quebec; Saskatchewan; Yukon. Puerto Rico. United States (USA) - Alabama; Alaska; Arizona; Arkansas; California; Colorado; Connecticut; Delaware; Florida; Georgia; Hawaii; Idaho; Illinois; Indiana; Iowa; Kansas; Kentucky; Louisiana; Maine; Maryland; Massachusetts; Michigan; Minnesota; Mississippi; Missouri; Montana; Nebraska; Nevada; New Hampshire; New Jersey; New Mexico; New York; North Carolina; North Dakota; Ohio; Oklahoma; Oregon; Pennsylvania; Rhode Island; South Carolina; South Dakota; Tennessee; Texas; Utah; Vermont; Virginia; Washington; West Virginia; Wisconsin; Wyoming. US Virgin Islands. British Virgin Islands.\n- bounds: (167.65, 14.92, -40.73, 86.45)\nDatum: North American Datum 1983\n- Ellipsoid: GRS 1980\n- Prime Meridian: Greenwich\n\n\n\n\n\n\n\n\n\nDate Summary: The 2020 TIGER/Line Arizona County Subdivisions dataset provides detailed administrative boundary information for the 61 county subdivisions in Arizona. It is available as a GeoDataFrame containing multiple attributes including geographic identifiers (GEOID), names, legal/statistical area descriptions, and precise boundary geometries. The dataset uses the NAD83 (EPSG:4269) coordinate system and is updated annually as part of the U.S. Census Bureau’s TIGER/Line program.\n\n# Plot Phoenix area together with a base map\n\n# Initialize figure\nfig, ax = plt.subplots(figsize =(10, 10))\n\n# Plot city boundary\nphoenix.boundary.plot(ax=ax,\n                     color='blue')\n# Add base map\nctx.add_basemap(ax=ax, \n                # source=ctx.providers.CartoDB.Voyager, \n                crs=phoenix.crs)\n\n# Clean map\nax.set_title('Map of Phoenix')\nax.axis('off')\nax.legend(phoenix['NAME'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Save file as GeoJSON for reproducibility\nphoenix.to_file('data_clean/phoenix-boundary-file', driver='GeoJSON')\n\nNow that we have Phoenix boundary mapped, we can move on to the Biodiversity Index dataset.\n\nAccess BII data from MPC\n\nWorkflow: - Define bounding box and time range for search - Open MPC catalog - Search MPC catalog for io_biodiversity collection with bounding box and time_range - Retrive search items - Select unique search item - Examine item.assets keys and title - Display pre-rendered image - Save data\n\n# Define study extent and time range\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]\ntime_range = \"2017-01-01/2020-01-01\"\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n# Search for collection \nsearch = catalog.search(\n    collections=['io-biodiversity'],\n    bbox=bbox,\n    datetime=time_range)\nsearch\n\n# Retrieve items\nitems = search.item_collection()\nitems\n# Determine number of items in search\nprint(f'There are {len(items)} items in the search.')\n\nThere are 4 items in the search.\n\n\n\nitem=items[0]\n# Check assets in item \nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\ndata -- Biodiversity Intactness\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\n\n# Plot rendered preview\nImage(url=item.assets['rendered_preview'].href, width=500)\n\n\n\n\nIt seems that our biodiversity data is larger than phoenix. Let’s access the BII data and clip to study extent"
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html#clip-raster-to-geometry",
    "href": "posts/2025-02-03-urban-biodiversity/index.html#clip-raster-to-geometry",
    "title": "Impact of Urbanization on Biodiversity",
    "section": "Clip raster to geometry",
    "text": "Clip raster to geometry\n\n# Explore data \nprint(type(items))\nprint(len(items))\nprint(items[0].assets['data'].href)\n\n&lt;class 'pystac.item_collection.ItemCollection'&gt;\n4\nhttps://pcdata01euw.blob.core.windows.net/impact/bii-v1/bii_2020/bii_2020_34.74464974521749_-115.38597824385106_cog.tif?st=2024-12-08T00%3A17%3A42Z&se=2024-12-09T01%3A02%3A42Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-12-08T03%3A52%3A20Z&ske=2024-12-15T03%3A52%3A20Z&sks=b&skv=2024-05-04&sig=aPPNFKqsw8IBhVdRMBurGkpa2RhJ7mc6qWmptB3E37s%3D\n\n\nThere’s only 1 dimension for band so it’s efficient to drop it using the squeeze() and .drop_vars()\n\n# Select and process 2020 and 2017 data \nfor idx in [0, 3]:\n    # Load data\n    bii = rioxr.open_rasterio(items[idx].assets['data'].href)\n    # Drop band dimension \n    bii = bii.squeeze().drop_vars('band')\n    \n    # Match CRS and clip\n    phoenix_match = phoenix.to_crs(bii.rio.crs)\n    assert phoenix_match.crs == bii.rio.crs\n    \n    # Clip the raster to phoenix geometry\n    year = '2020' if idx == 0 else '2017'\n    globals()[f'bii_{year}_phoenix'] = (bii.rio.clip_box(*phoenix_match.total_bounds)\n                                    .rio.clip(phoenix_match.geometry))\n\n\n# Check clipped data\nprint(bii_2020_phoenix)\nbii_2020_phoenix.plot()\n\n&lt;xarray.DataArray (y: 583, x: 990)&gt; Size: 2MB\narray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\nCoordinates:\n  * x            (x) float64 8kB -112.5 -112.5 -112.5 ... -111.6 -111.6 -111.6\n  * y            (y) float64 5kB 33.81 33.81 33.81 33.81 ... 33.29 33.29 33.29\n    spatial_ref  int64 8B 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0"
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html#calculate-percent-area-with-bii-0.75",
    "href": "posts/2025-02-03-urban-biodiversity/index.html#calculate-percent-area-with-bii-0.75",
    "title": "Impact of Urbanization on Biodiversity",
    "section": "Calculate percent area with BII >0.75",
    "text": "Calculate percent area with BII &gt;0.75\nTo calculate percent area, we need total pixel counts of phoenix and then pixel counts with BII &gt;= 0.75.\n\n# Count total Phoenix pixels\ntotal_counts = bii_2020_phoenix.count().item()\nprint(f\"There are {total_counts} pixels in Phoenix\")\n# Select BII &gt;= 0.75\nover75_2020 = (bii_2020_phoenix &gt;= 0.75).astype(int)\nover75_2017 = (bii_2017_phoenix &gt;= 0.75).astype(int)\n\nThere are 338699 pixels in Phoenix\n\n\n\n# Count threshold pixels in 2020 \nvalue, counts = np.unique(over75_2020, return_counts=True)\nassert len(value) == len(counts)\n# Initialize dictionary with column's data\ndic = {'code': value,\n       'counts': counts}\n# Create a data frame \npix_counts_20 = pd.DataFrame(dic)\npix_counts_20\n# Report findings\nprint(f\"There are {pix_counts_20.iloc[1,1]} pixels with BII &gt;= 0.75 in 2020\")\n\nThere are 21986 pixels with BII &gt;= 0.75 in 2020\n\n\nWhile it’s easy to run the same code for 2017, it’s better to write a for loop to maintain best coding practice.\n\n# Count pixels with condition\nyears = {'2020': over75_2020, '2017': over75_2017}  # map years to their data\n\nfor year, data in years.items():\n    # Count pixels for True/False\n    value, counts = np.unique(data, return_counts=True)\n    assert len(value) == len(counts)\n    \n    # Create dataframe\n    dic = {'code': value, 'counts': counts}\n    globals()[f'pix_counts_{year[-2:]}'] = pd.DataFrame(dic)  # creates pix_counts_20 and pix_counts_17\n    \n    # Save counts as variable\n\n    globals()[f'counts_75_{year}'] = counts[1]\n        \n    # Report findings\n    print(f\"There are {counts[1]} pixels with BII &gt;= 0.75 in {year}\")\n\nThere are 21986 pixels with BII &gt;= 0.75 in 2020\nThere are 24133 pixels with BII &gt;= 0.75 in 2017\n\n\n\n# Plot the data to check extent\nover75_2017.plot()\n\n\n\n\n\n\n\n\nNow that we have pixel counts of both total cells in Phoenix and BII &gt; 75% cells, we can calculate the percent area with a simple division.\n\n# Write a \"for loop\" to run calculation for both years\nratio_2017 = round((counts_75_2017/total_counts)*100, 2)\nratio_2017\n\n7.13\n\n\n\nfor year in years:\n    # Calculate ratio\n    globals()[f'ratio_{year}'] = (globals()[f'counts_75_{year}']/total_counts) * 100\n    # Print result\n    print(f\"In {year}, {globals()[f'ratio_{year}']:.2f}% of pixels have BII &gt;= 0.75\")\n\nIn 2020, 6.49% of pixels have BII &gt;= 0.75\nIn 2017, 7.13% of pixels have BII &gt;= 0.75\n\n\n\n# Obtain BII loss between 2017 to 2020\nloss = over75_2017 - over75_2020\nloss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 583, x: 990)&gt; Size: 5MB\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\nCoordinates:\n  * x            (x) float64 8kB -112.5 -112.5 -112.5 ... -111.6 -111.6 -111.6\n  * y            (y) float64 5kB 33.81 33.81 33.81 33.81 ... 33.29 33.29 33.29\n    spatial_ref  int64 8B 0xarray.DataArrayy: 583x: 9900 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])Coordinates: (3)x(x)float64-112.5 -112.5 ... -111.6 -111.6axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-112.469598, -112.468699, -112.467801, ..., -111.58296 , -111.582062,\n       -111.581164])y(y)float6433.81 33.81 33.81 ... 33.29 33.29axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([33.813546, 33.812648, 33.811749, ..., 33.292523, 33.291625, 33.290726])spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-112.47004683159909 0.0008983152841195194 0.0 33.81399511086966 0.0 -0.0008983152841195182array(0)Indexes: (2)xPandasIndexPandasIndex(Index([-112.46959767395703, -112.46869935867291, -112.46780104338879,\n       -112.46690272810467, -112.46600441282054, -112.46510609753642,\n        -112.4642077822523, -112.46330946696818, -112.46241115168407,\n       -112.46151283639995,\n       ...\n        -111.5892486955199, -111.58835038023577, -111.58745206495165,\n       -111.58655374966753, -111.58565543438341,  -111.5847571190993,\n       -111.58385880381518, -111.58296048853106, -111.58206217324694,\n       -111.58116385796282],\n      dtype='float64', name='x', length=990))yPandasIndexPandasIndex(Index([  33.8135459532276, 33.812647637943485,  33.81174932265937,\n        33.81085100737524,  33.80995269209112, 33.809054376807005,\n        33.80815606152289,  33.80725774623877,  33.80635943095465,\n       33.805461115670525,\n       ...\n       33.298811295427114, 33.297912980142996,  33.29701466485888,\n        33.29611634957476,  33.29521803429064,  33.29431971900652,\n         33.2934214037224,  33.29252308843828,  33.29162477315416,\n        33.29072645787004],\n      dtype='float64', name='y', length=583))Attributes: (0)\n\n\nValue in loss variable represents change of BII between the years. 1 indicates BII loss, and -1 indicates BII gain, 0 means no change.\n\n# Select xarray cells with value of 1 \nloss = loss.where(loss==1)\nloss\nloss.plot()\n\n\n\n\n\n\n\n\n\nVisualize biodiversity loss\n\n# Define aspect ratio with height and width\naspect = bii_2020_phoenix.rio.width/bii_2020_phoenix.rio.height\n\n# Initialize figure\nfig, ax = plt.subplots(figsize=(10, 4*aspect))\n\n# Plot the BII raster in 2020\nbii_2020_phoenix.plot(ax=ax,\n                     cbar_kwargs={\n                    \"orientation\": \"horizontal\",\n                    \"label\": \"BII for 2020\"}\n                     )\n\n# Plot the loss layer\nloss.plot(ax=ax,\n         cmap=\"inferno\",\n         add_colorbar=False)\n\n# Plot city boundary\nphoenix.boundary.plot(ax=ax,\n                     color='blue')\n\n# Set legend for change raster\nred_patch = mlines.Line2D([], [], color = \"red\", \n                          label = \"Biodiversity area loss\", \n                          linewidth = 4)\n\nax.legend(handles = [red_patch],\n          bbox_to_anchor=(0, 0, 0.75, 0),\n         fontsize = 8)\n\n# Set title\nax.set_title(\"Biodiversity Intactness Index (BII) \\nPhoenix Subdivision\")\n\n# Turn axis off\nax.axis(\"off\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThis figure shows the Biodiversity Intactness Index (BII) for the Phoenix Subdivision in 2020. The BII values are displayed using a color gradient scale ranging from 0.1 to 0.8. The area is outlined in blue, showing the subdivision boundaries. Quantitative analysis reveals a decline in high-biodiversity areas between 2017 and 2020. In 2017, 7.13% of the area had high biodiversity intactness (BII ≥ 0.75), which decreased to 6.49% by 2020. This decline is visually represented by the red areas marking “Biodiversity area loss,” which appear in two main locations: a larger area in the northeastern section of the subdivision and another smaller cluster in the southern portion."
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html",
    "href": "posts/2025-02-18-plant-classifier/index.html",
    "title": "Florida Palmetto Species Classifier",
    "section": "",
    "text": "Saw-palmetto growing under an upland pine forest. Photo by Southwest Florida Water Management District"
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html#about",
    "href": "posts/2025-02-18-plant-classifier/index.html#about",
    "title": "Florida Palmetto Species Classifier",
    "section": "About",
    "text": "About\nSaw palmetto (Serenoa repens) and scrub palmetto (Sabal etonia) are both keystone species in south-central Florida that support the pine flatwoods ecosystem. This analysis uses logistic regression to classify these two native palmetto species based on plant characteristics. The goal is to evaluate whether variables such as plant height, canopy dimensions, and the number of green leaves can effectively predict species classification. The highlight of this study includes data visualization, logistic regression modeling, and models assessment with cross-validation.\n\nData Summary\nPalmetto Monitoring Data The dataset used for this analysis can be accessed through EDS Data Portal. It provides detailed measurements of the growth and survival characteristics of Serenoa repens and Sabal etonia, two prominent palmetto species in Florida. The specific variables included in the dataset are:\n\n\n\n\n\n\n\n\nColumn Name\nDescription\nType\n\n\n\n\nyear\nSample year.\ndate\n\n\nplant\nPlant ID number.\nfloat\n\n\nspecies\nPalmetto species (Serenoa repens or Sabal etonia).\nstring\n\n\nsite\nSite name.\nstring\n\n\nhabitat\nHabitat type.\nstring\n\n\ntreatment\nExperimental treatment applied.\nstring\n\n\nsurvival\nSurvival from previous census (1981–2017).\nstring\n\n\nheight\nMaximum height (1981–2017).\nfloat\n\n\nlength\nWidest length of the canopy (1981–2017).\nfloat\n\n\nwidth\nWidest width of the canopy perpendicular to the canopy length (1981–2017).\nfloat\n\n\ngreen_lvs\nCount of green leaves (1981–2017).\nfloat\n\n\nscape\nCount of inflorescence scapes (1981–2017).\nfloat\n\n\nnew_lvs\nCount of new leaves (1982–2017).\nfloat\n\n\nbiomass\nCalculated biomass estimate of dry mass (1989–2017).\nfloat\n\n\ncanopy\nAverage percent canopy cover across the four cardinal directions, taken in January 1993.\nfloat\n\n\nlf_long\nLeaf longevity (1990–1997).\nfloat\n\n\ncomments\nNotes made in 2017.\nstring\n\n\n\n\n\nData Citation:\nAbrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5\n\n\nAnalysis Outline\n\nData Exploration\nTrain Logistic Regression Models\nK-fold Cross-Validation\nModel Assessment\nPredict with Best Performaing Model\nTest Classification Accuracy"
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html#set-up",
    "href": "posts/2025-02-18-plant-classifier/index.html#set-up",
    "title": "Florida Palmetto Species Classifier",
    "section": "Set-up",
    "text": "Set-up\nWe will use the following libraries and set-up through this analysis\n\n\nCode\n# Import libraries\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(here)\nlibrary(cowplot)\nlibrary(patchwork)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(stats)\nlibrary(yardstick)"
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html#data-exploration",
    "href": "posts/2025-02-18-plant-classifier/index.html#data-exploration",
    "title": "Florida Palmetto Species Classifier",
    "section": "Data Exploration",
    "text": "Data Exploration\nFrom the metadata, code 1 represents Serenoa repens, code 2 represents Sabal etonia. We will first load the dataset and preprocess the data by selecting the relevant columns and removing missing values, then factorize the string type species column into dummy variables: 0 for Serenoa repens and 1 for Sabal etonia.\n\n\nCode\n# Load the dataset\ndf &lt;- read_csv(here(\"posts\",\"2025-02-18-plant-classifier\",\"data\", \"palmetto.csv\"))\n# Preprocess data\ndf_clean &lt;- df %&gt;% \n  select(species, height, length, width, green_lvs) %&gt;%\n  drop_na() %&gt;%\n  mutate(species = factor(species, levels = c('1','2'), labels = c(0, 1)))\nkable(head(df_clean), title = \"Palmetto Data cleaned\")\n\n\n\n\n\nspecies\nheight\nlength\nwidth\ngreen_lvs\n\n\n\n\n0\n51\n69\n63\n6\n\n\n1\n79\n129\n71\n3\n\n\n0\n80\n90\n66\n6\n\n\n1\n59\n80\n72\n2\n\n\n0\n83\n96\n79\n6\n\n\n1\n93\n119\n90\n2\n\n\n\n\n\n\nHistograms\nBoth species exhibit overlapping distributions for height, width, and length, indicating these variables alone may not perfectly distinguish between Serenoa repens and Sabal etonia.\n\nHeight (Figure 1): The height distribution of Sabal etonia is slightly higher than that of Serenoa repens.\nWidth (Figure 2): Sabal etonia shows a slightly higher peak in the middle range (100–120 cm) compared to Serenoa repens.\nLength (Figure 3): Significant overlap exists, but Sabal etonia tends to grow longer (100–200 cm), while Serenoa repens is more concentrated in shorter lengths (&lt;200 cm).\nGreen Leaves (Figure 4): Serenoa repens generally has more green leaves than Sabal etonia, highlighting a potential growth pattern difference.\n\n\n\nCode\n##| fig-cap: \"Figure 1: Histogram of Height by Species\"\n#| fig-subcap: \"This histogram shows the distribution of plant height (in cm) for two species of palmetto: Serenoa repens (red bars) and Sabal etonia (blue bars). The x-axis represents plant height, while the y-axis represents the count of plants within each height bin.\"\n\n# height comparison\nheight &lt;- ggplot(df_clean, aes(x=height, fill = species)) +\n  geom_histogram(position =\"dodge\", alpha = 0.8) +\n  labs(title = \"Height Distribution by Species\", \n       x = \"Height (cm)\", \n       y = \"Count\",\n       fill = \"Species\") +\n  scale_fill_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n#ggplot(df_clean, aes(x=height, fill = species)) +\n#  geom_histogram(position =\"identity\", alpha = 0.5)\n\n##| fig-cap: \"Figure 2: Histogram of Width (in cm) by Species\"\n#| fig-subcap: \"This histogram shows the distribution of plant width (in cm) for two species of palmetto: Serenoa repens (red bars) and Sabal etonia (blue bars). The x-axis represents plant height, while the y-axis represents the count of plants within each height bin.\"\n# width comparison\nwidth &lt;- ggplot(df_clean, aes(x=width, fill = species)) +\n  geom_histogram(position =\"dodge\", alpha = 0.8) +\n  labs(title = \"Width Distribution by Species\", \n       x = \"Width (cm)\", \n       y = \"Count\",\n       fill = \"Species\") +\n  scale_fill_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n##| fig-cap: \"Figure 3: Histogram of Maximum Canopy Length by Species\"\n#| fig-subcap: \"The chart highlights subtle differences in growth patterns between the two species, with Sabal etonia tending to grow longer canopy than Serenoa repens. \"\n# length comparison\nlength &lt;- ggplot(df_clean, aes(x=length, fill = species)) +\n  geom_histogram(position =\"dodge\", alpha = 0.8) +\n  labs(title = \"Length Distribution by Species\", \n       x = \"Length (cm)\", \n       y = \"Count\",\n       fill = \"Species\") +\n  scale_fill_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\")) +\n  theme_minimal() +\n  theme(legend.position = \"none\") \n\n##| fig-cap: \"Figure 4: Green Leaves Counts by Species\"\n#| fig-subcap: \"Differences in growth patterns between the two species is shown here, with Sabal etonia tending to grow less green leaves than Serenoa repens.\"\n# leaves comparison\nleaves &lt;- ggplot(df_clean, aes(x=green_lvs, fill = species)) +\n  geom_histogram(position =\"dodge\", alpha = 0.8) +\n  labs(title = \"Number of Green Leaves by Species\", \n       x = \"Number of Green Leaves\", \n       y = \"Count\",\n       fill = \"Species\") +\n  scale_fill_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\")) +\n  theme_minimal() +\n  theme(legend.position = \"right\") \n\n\n\n\nCode\nheight + width + length + leaves\n\n\n\n\n\nFigure 1 - 4: Plant Characteristics by Species\n\n\n\n\n\n\nPaired Scatter Plots\nWe will create paired scatter plots to visualize the relationship between plant characteristics. The scatter plots show the relationship between green leaves and width (Figure 5) and height and canopy length (Figure 6). The plots are colored by species to highlight differences in growth patterns. The scatter plot of green leaves vs. width (Top) shows less overlap compared to the height vs. canopy length plot (Bottom), indicating that green leaves and width may be more useful for species classification. However, all variables exhibit some degree of overlap, emphasizing the need for a combination of predictors to improve classification accuracy.\n\n\nCode\n# leaves vs. width\np1 &lt;- ggplot(df_clean, aes(x = width, y = green_lvs, color = species)) +\n  geom_point(alpha = 0.6) +\n  labs(\n    title = \"Green Leaves vs. Width by Species\",\n    x = \"Width (cm)\",\n    y = \"Number of Green Leaves\",\n    color = \"Species\"\n  ) +\n  \n  scale_color_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\")) +\n  theme(legend.position = \"none\") +\n  theme_minimal()\n\n# Height vs. Length\np2 &lt;- ggplot(df_clean, aes(x = height, y = length, color = species)) +\n  geom_point(alpha = 0.6) +\n  labs(\n    title = \"Height vs. Canopy Length by Species\",\n    x = \"Height (cm)\",\n    y = \"Max Canopy Length (cm)\",\n    color = \"Species\"\n  ) +\n  scale_color_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\")) +\n  theme(legend.position = \"right\") +\n  theme_minimal() \n  \np1/p2\n\n\n\n\n\nFigure 5 & 6: Scatter Plots of Paired Plant Characterstics\n\n\n\n\n\n\nCorrelation Heat Map\nThen, we will use a heatmap to visualize the pairwise correlations among all numeric variables in the palmetto dataset. The heatmap suggests that height, length, canopy, biomss and width are highly positively correlated, which can be explained by larger plants having larger dimensions and more biomass. The variable species shows a negatively correlation with green_lvs, new_lvs and biomass, with the strength of correlation descending in that order.\n\n\nCode\n# try a heatmap\n# Select numeric columns for correlation analysis\nnumeric_features &lt;- df[sapply(df, is.numeric)]\nnumeric_features &lt;- numeric_features[, !(colnames(numeric_features) %in% c(\"year\", \"site\", \"survival\",\"plant\"))]\n# Compute the correlation matrix\ncor_matrix &lt;- cor(numeric_features, use = \"complete.obs\")\n\n# Convert the correlation matrix to a long format for ggplot2\ncor_data &lt;- as.data.frame(as.table(cor_matrix))\n\n# Create the heatmap\nggplot(cor_data, aes(Var1, Var2, fill = Freq)) +\n  geom_tile(color = \"white\") +  # Add gridlines\n  scale_fill_gradient2(low = \"lightblue\", high = \"salmon\", mid = \"white\", midpoint = 0, \n                       limit = c(-1, 1), space = \"Lab\", name = \"Correlation\") +\n  labs(title = \"Correlation Heatmap of Palmetto Data\", x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\nFigure 7: Pairwise Correlation Heatmap of Palmetto Data"
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html#train-logistic-regression-models",
    "href": "posts/2025-02-18-plant-classifier/index.html#train-logistic-regression-models",
    "title": "Florida Palmetto Species Classifier",
    "section": "Train Logistic Regression Models",
    "text": "Train Logistic Regression Models\n\nData Split\nWe will split the data into training and testing sets using a 70/30 split and check for class imbalance.\n\n\nCode\nset.seed(123)\n# Split the data\ndf_split &lt;- initial_split(df_clean, prop = 0.7, strata = species)\ndf_train &lt;- training(df_split)\ndf_test &lt;- testing(df_split)\n\n# Check class imbalance\ntrain_class &lt;- df_train %&gt;%\n  group_by(species) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(prop = n / sum(n)) \n\ntest_class &lt;- df_test %&gt;%\n  group_by(species) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(prop = n / sum(n)) \n\n\n\n\nModel Training\nSet engine\n\n\nCode\n# initiate model \nlog &lt;- logistic_reg() %&gt;%\n  set_engine(\"glm\") %&gt;%\n  set_mode(\"classification\")\n\n\nModel 1: log odds of species based on height, length, width and leaves as predictor variables.\n\n# Create recipe\nrec_1 &lt;- recipe(species ~ height + length + width + green_lvs, data = df_train) \n\n# Fit model with training data\nlog_1 &lt;- workflow() %&gt;%\n  add_recipe(rec_1) %&gt;%\n  add_model(log) \n\nlog_1_fit &lt;- log_1 %&gt;%\n  fit(data = df_train)\n\nModel 2: log odds of species based on height, width and green leaves as predictor variables.\n\nrec_2 &lt;- recipe(species ~ height + width + green_lvs, data = df_train) \n\nlog_2 &lt;- workflow() %&gt;%\n  add_recipe(rec_2) %&gt;%\n  add_model(log) \nlog_2_fit &lt;- log_2 %&gt;%\n  fit(data = df_train)\n\n\n\nCompare models using K-fold Cross-Validation\nRandomly divide training data into k groups, train models with k-1 folds, leaving one out for validation. Compute performance metrics for k number of models. Average k test errors to get an estimate of the model’s performance on unseen data.\nModel 1\n\n# Split training data \nfolds &lt;- vfold_cv(df_train, v = 10, strata = species)\n\n# Fit models with 9 folds and evaluate on the remaining fold\nlog_1_folds &lt;- log_1 %&gt;% \n  fit_resamples(folds)\n\n# Calculate model performance\nm1_metrics &lt;- collect_metrics(log_1_folds)\n\nModel 2\n\nlog_2_folds &lt;- log_2 %&gt;% \n  fit_resamples(folds)\n\nm2_metrics &lt;- collect_metrics(log_2_folds)\n\nModel Comparison\n\n\nCode\n# Display tables \ncondensed_table &lt;- data.frame(\n  Model = c(\"Model 1\", \"Model 2\"),\n  Accuracy_Mean = c(m1_metrics$mean[1], m2_metrics$mean[1]),\n  ROC_AUC_Mean = c(m1_metrics$mean[3], m2_metrics$mean[3])\n)\nkable(condensed_table, title=\"Model Comparison\")\n\n\n\n\n\nModel\nAccuracy_Mean\nROC_AUC_Mean\n\n\n\n\nModel 1\n0.9180062\n0.9732010\n\n\nModel 2\n0.8998379\n0.9640701\n\n\n\nModel Comparison\n\n\nFrom 10 fold cross-validation, Model 1 has a higher accuracy and ROC AUC compared to Model 2, suggesting that model 1 is better at classification."
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html#train-best-model",
    "href": "posts/2025-02-18-plant-classifier/index.html#train-best-model",
    "title": "Florida Palmetto Species Classifier",
    "section": "Train Best Model",
    "text": "Train Best Model\n\n\nCode\n# Finalize the model using entire data set\nlog_1_final &lt;- log_1 %&gt;%\n  last_fit(split = df_split)\n\n# Extract actual models\nmodel_final &lt;- log_1_final %&gt;% \n  extract_fit_parsnip() \n  \nmodel_table &lt;- model_final %&gt;%\n  tidy() %&gt;% \n  mutate(\n    term = case_when(\n      term == \"height\" ~ \"Maximum Height\",\n      term == \"length\" ~ \"Maximum Canopy Length\",\n      term == \"width\" ~ \"Maximum Canopy Width\",\n      term == \"green_lvs\" ~ \"Count of Green Leaves\",\n      TRUE ~ term\n    ),\n    p.value = ifelse(as.numeric(p.value) &lt; 0.01,'&lt;0.01', as.character(p.value))\n  ) %&gt;% \n  mutate(p.value = as.character(p.value)) %&gt;%\n  kable(format = \"html\", caption = \"Logistic Regression Model Results\") %&gt;%\n  kable_styling(full_width = FALSE, bootstrap_options = c(\"striped\", \"hover\"))\nmodel_table\n\n\n\nLogistic Regression Model Results\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3.2721657\n0.1709524\n19.14081\n&lt;0.01\n\n\nMaximum Height\n-0.0285369\n0.0027702\n-10.30135\n&lt;0.01\n\n\nMaximum Canopy Length\n0.0471518\n0.0022824\n20.65872\n&lt;0.01\n\n\nMaximum Canopy Width\n0.0377992\n0.0025076\n15.07359\n&lt;0.01\n\n\nCount of Green Leaves\n-1.9338916\n0.0471980\n-40.97402\n&lt;0.01\n\n\n\n\n\n\n\nEach coefficient estimate shows how much the likelihood of the outcome being species Sabal etonia changes when the corresponding predictor increases by one unit."
  },
  {
    "objectID": "posts/2025-02-18-plant-classifier/index.html#classification-results",
    "href": "posts/2025-02-18-plant-classifier/index.html#classification-results",
    "title": "Florida Palmetto Species Classifier",
    "section": "Classification Results",
    "text": "Classification Results\nThis section evaluates how successfully the selected model would classify a plant as the correct species. I use a confusion matrix and histogram of predicted probabilities to assess the model’s performance.\n\nPredict with Model\n\n\nCode\n# Display the final table\nkable(summary_table, caption = \"Model Classification Results\")\n\n\n\nModel Classification Results\n\n\n\n\n\n\n\n\nspecies\ncorrectly_classified\nincorrectly_classified\npercent_correct\n\n\n\n\nSerenoa repens\n1669\n151\n92%\n\n\nSabal etonia\n1696\n165\n91%\n\n\n\n\n\n\n\nVisualize Results with Confusion Matrix\n\n\nCode\n# Make confusion matrix with true/false positive and true/false negative\nconf_matrix &lt;- result %&gt;%\n  conf_mat(truth = species, estimate = .pred_class)\n\ncm &lt;- autoplot(conf_matrix, type = \"heatmap\") +\n  scale_fill_gradient(low = \"salmon\", high = \"lightblue\") +\n  labs(\n    title = \"Confusion Matrix Heatmap\",\n    x = \"Predicted Species\",\n    y = \"Actual Species\"\n  ) +\n  scale_x_discrete(labels = c(\"Serenoa repens\", \"Sabal etonia\")) +  # Custom labels for x-axis\n  scale_y_discrete(labels = c(\"Sabal etonia\",\"Serenoa repens\")) +  # Custom labels for y-axis\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\", hjust = 0.5),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    legend.position = \"none\" \n  )\ncm\n\n\n\n\n\nFigure 8: Confusion Matrix Heatmap\n\n\n\n\n\n\nVisualize Results with Predicted Probability\n\n\nCode\n# Pivot result table for plotting\nresult_long &lt;- result %&gt;%\n  pivot_longer(cols = c(.pred_0, .pred_1), names_to = \"plant\", values_to = \"probability\")\n\n# Plot predicted probabilities\nprob_p &lt;- ggplot(result, aes(x=.pred_1, fill = as.factor(species)))+\n  geom_density(stat ='density',position=\"identity\",alpha=0.7)+\n  labs(title=\"Density Plot of Predicted Probabilities\",\n       x=\"Predicted Probability of Sabal etonia\",\n       y=\"Frequency\",\n       fill=\"Species\")+\n  scale_fill_manual(values = c(\"0\" = \"#964B00\", \"1\" = \"skyblue\"),\n                    labels = c(\"Serenoa repens\", \"Sabal etonia\"))+\n  theme_minimal()+\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\", hjust = 0.5),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    legend.position = \"right\" \n  )\nprob_p \n\n\n\n\n\nFigure 9: Density Plot of Predicted Probabilities\n\n\n\n\n\n\nDiscussion\nThis study utilizes plant height (in cm), canopy length (in cm), canopy width (in cm), and the count of green leaves to develop a regression model aimed at predicting two closely related plant species. The results indicate promising accuracy, achieving 91.7% for Serenoa repens and 91.13% for Sabal etonia. The model’s sensitivity is calculated as 91.83%, indicating its ability to correctly identify positive cases, while its specificity is 91.01%, reflecting its accuracy in identifying negative cases."
  },
  {
    "objectID": "posts/2025-01-24-wildfire-analysis/index.html",
    "href": "posts/2025-01-24-wildfire-analysis/index.html",
    "title": "Understanding Wildfire Impact",
    "section": "",
    "text": "GitHub Repository with Full Analysis\n Image credits: NASA\n\nAbout\nThe hillsides of Los Angeles are once again shrouded in smoke as wildfires rage, turning familiar landscapes into scenes of devastation. Beyond the flames, the air itself becomes a silent hazard, the impacts of smoke and poor air quality linger, posing significant risks to public health and the environment.\nLooking back at the devastating 2017 Thomas Fire, one of California’s largest wildfires, we gain valuable insights into the aftermath of such events. It consumed 281,893 acres across Santa Barbara and Ventura counties, destroying hundreds of structures and significantly impacting local ecology and regional air quality. This blog revisits those findings and bridges them to the ongoing crisis in Los Angeles. Through this work, we aim to contribute to the growing body of knowledge about wildfire impacts and recovery patterns in California’s coastal regions.\nThe analysis demonstrates the application of geospatial analysis techniques in environmental monitoring, and provides insights into the environmental and public health impacts of large-scale wildfires in California’s changing climate.\n\n\nHighlights\n\nFalse-Color Imaging: Visualized vegetation health and burn scars using Landsat multispectral bands, revealing insights into fire severity and ecological recovery.\nAir Quality Assessment: Quantified the Thomas FIre’s impact on AQI in Santa Barbara County, using time-series data to illustrate pollution trends during and after the fire.\nGeospatial Analysis: Leveraged Python libraries for geospatial processing, including geopandas, xarray, and rasterio.\n\n\n\nDatasets\n\nLandsat Surface Reflectance Data\nSource: Microsoft Planetary Computer - Landsat Collection 2 Level-2 This data contains Red, Green, Blue (RGB), Near-Infrared(NIR), and Shortwave Infrared (SWIR) bands. Pre-processed to remove data outside study area and coarsen the spatial resolution. False color image created by using the short-wave infrared (swir22), near-infrared, and red variables.\nAir Quality Index (AQI) Data\nSource: Environmental Protection Agancy (EPA) - Air Data This data contains daily AQI values for Santa Barbara County from 2017 to 2018.\nThomas Fire perimeter data Source: CalFire The database includes information on fire date, managing agency, cause, acres, and the geospatial boundary of the fire, among other information. This data was pre-processed to select only the Thomas fire boundary geometry.\n\n\n\nSet Up\nWe will use the following libraries and set-up through this analysis\n\n# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os \nimport geopandas as gpd\nimport rioxarray as rioxr\nimport xarray as xr\nimport matplotlib.patches as mpatches \n\n\n# Set option to display all columns\npd.set_option('display.max_columns', None)\n\n\n\nPart 1: Visualizing Burn Scars\nObjective:\nWe will create a false-color image of the Thomas Fire to explore how remote sensing and data visualization aid environmental monitoring. False-color imagery, using infrared bands, highlights vegetation health, burn severity, and fire scars. This helps assess recovery, identify risks, and plan restoration.\n\nImport Data\n\n# Import landsat nc data\nlandsat = rioxr.open_rasterio('data/landsat8-2018-01-26-sb-simplified.nc')\n# Import fire boundary shapefile\nthomas = gpd.read_file('data/thomas-fire-boundary-file')\n\n\n\nPrepare data for mapping\nClean redundant dimension of landsat data\n\n# Remove any length 1 dimension and its coordinates\nlandsat = landsat.squeeze().drop_vars('band')\n\nAfter data wrangling we are ready for mapping. But first we need to ensure coordinate reference systems (CRS) of spatial data are matched.\n\n\n# Match CRS for plotting\nthomas = thomas.to_crs(landsat.rio.crs)\n\n# Test for matching CRS\nassert landsat.rio.crs == thomas.crs\n\nBecause Landsat data is downloaded with a estimated box, it’s going to be larger than the thomas fire boundary. We clip landsat with thomas fire boundary to focus on study area.\n\nthomas_landsat = landsat.rio.clip_box(*thomas.total_bounds)\n\nObtain aspect ratio with height and width to avoid distortion when mapping\n\n# Print height and width of landsat data\nprint('Height:', thomas_landsat.rio.height)\nprint('Width:', thomas_landsat.rio.width)\n\n# Calculate aspect ratio for plotting \naspect_ratio = thomas_landsat.rio.width/thomas_landsat.rio.height\naspect_ratio\n\nHeight: 149\nWidth: 259\n\n\n1.738255033557047\n\n\n\n\nMap the Thomas Fire Scar\n\n# Initialize figure\nfig, ax = plt.subplots(figsize = (8, 6*aspect_ratio))\n\n# Plot landsat map by calling false image bands\n(thomas_landsat[['swir22', 'nir08', 'red']]\n .to_array()\n .plot.imshow(ax=ax,\n              robust=True))\n\n# Overlay thomas fire boundary \nthomas.boundary.plot(ax=ax,\n                    edgecolor=\"blue\",\n                    linewidth=1,\n                    label='Thomas Fire Boundary')\n\n# Add legend\n# Create a legend for the false color bands and boundary\nlegend_swir = mpatches.Patch(color = \"#eb6a4b\", label = 'Shortwave Infrared \\n - Burned Area')\nlegend_nir = mpatches.Patch(color = \"#a1fc81\", label = 'Near Infrared \\n - Vegetation')\nlegend_bound = mpatches.Patch(color = \"blue\", label = 'Thomas Fire Boundary')\n# Clean up map\nax.legend(handles = [legend_swir, legend_nir, legend_bound], loc = 'upper right')\nax.set_title('False Color Map with the Thomas Fire Boundary')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1. False Color Map of the 2017 Thomas Fire\nThis map displays the 2017 Thomas Fire region using false-color imagery derived from Landsat data. The pinkish/salmon colored area within the blue boundary line represents the burn scar from the Thomas Fire. The bright green areas surrounding the burn scar represent healthy, unburned vegetation. Using SWIR (shortwave infrared), NIR (near infrared), and red bands is particularly effective for burn scar analysis because:\n\nSWIR is sensitive to burn scars and can penetrate smoke\nNIR helps distinguish between burned and unburned vegetation\nRed light helps with overall land feature distinction\n\nThis visualization enhances the identification of burn scars, vegetation health, and moisture content.\n\n\n\nPart 2: Analyzing Fire Impact on AQI\nObjective:\nThis part of the analysis shows the dramatic impact of the Thomas Fire on Santa Barbara’s air quality. The study built time series visualization showing clear air quality change during fire period. A 5 day rolling averages is created to smooth daily fluctuations and identify trends.\n\nImport Data\n\n# Read in data\naqi_17 = pd.read_csv('data/daily_aqi_by_county_2017.zip', compression='zip')\naqi_18 = pd.read_csv('data/daily_aqi_by_county_2018.zip', compression='zip')\n\n\n\nPrepare AQI Tables for Analysis\nWe combined AQI data from 2017-2018 to analyze air quality trends during the Thomas Fire period. After merging the datasets, we filtered specifically for Santa Barbara County and removed unnecessary columns to streamline the analysis.\n\n# concatenate tables\naqi = pd.concat([aqi_17,aqi_18])\n\n# Clean column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_'))\n\n# Select data from SB county and store as variable\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara'] \n\n# Drop unnecessary columns in SB\naqi_sb = aqi_sb.drop(columns=['state_name','county_name','state_code','county_code'])\n\n# Verify operations \naqi_sb.head(3)\n\n\n\n\n\n\n\n\ndate\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\n\n\n\n\n28648\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n\n\n28649\n2017-01-02\n39\nGood\nPM2.5\n06-083-2011\n11\n\n\n28650\n2017-01-03\n71\nModerate\nPM10\n06-083-4003\n12\n\n\n\n\n\n\n\n\n\nTime Series Processing\nTo address daily fluctuations and provide a clearer trend, we will implement a 5-day rolling average. This method smooths the data by averaging values over a sliding 5-day window, ensuring that short-term variations are minimized while preserving the overall pattern in the dataset.\n\n# Convert dates to datetime date type\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n                     \n# Assign date column as index\naqi_sb = aqi_sb.set_index('date')\n\n# Define a new column in aqi_sb\naqi_sb['five_day_average'] = aqi_sb['aqi'].rolling('5D').mean()\n\n\n\nVisualization\nWe can create a visualization that displays daily AQI values alongside the smoothed 5-day rolling average, using matplotlib. This plot provides a clear view of short-term fluctuations and overall trends.\n\n# Create a plot\n\nax = (aqi_sb.drop(columns='number_of_sites_reporting') # Drop unnecessary column\n        .plot(title='Daily AQI and 5-day average AQI in Santa Barbara from 2017 to 2018',\n              ylabel='Air Quality Index',\n              color=['salmon','blue'] \n)\n)                                     \n# Show the date of the Thomas fire\nplt.axvline(x = '2017-12-04', \n            color = 'red', \n            linestyle = 'dashed', \n            label = \"Thomas Fire\")   \nplt.legend()                  \n\n\n\n\n\n\n\n\nFigure 2. Daily AQI and 5-day AQI averages in Santa Barbara County\nDuring the peak fire period in December 2017, AQI values spiked significantly above normal levels. The 5-day rolling average helps smooth out daily fluctuations while still highlighting the severe deterioration in air quality during the fire. Outside of the fire period, Santa Barbara generally maintained good air quality with AQI values typically below 100. This makes the fire’s impact even more striking, as 5-day AQI values rose well above 200 during the incident."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi there! I’m Zoe Zhou, my Chinese name 周佳瑞 is pronounced as “Jo jar-ray”. I’m a graduate student at the Bren School of Environmental Science & Management at UCSB.\nThis site is a reflection of my passions. Here, you’ll find:\n\nProjects where I unravel patterns and tell stories hidden in data.\nA Photography Gallery filled with snapshots of natural beauty and candid moments.\nInsights into my journey, aspirations, and maybe even a few experiments (both in data and life).\n\nI’m on a mission to merge the power of data with the beauty of nature, finding stories in numbers and moments in the wild.\nWhether you’re here for inspiration, collaboration, or simply to wander, I’m excited to have you along for the ride.\n\n\nBackground\nI graduated from the University of Washington in 2016 with Bachelor of Science degrees in Economics and Earth Science, a combination that shaped my approach to tackling environmental problems as a conservation project officer.\nOver the years, I’ve led coastal conservation projects on Hainan Island, China, leveraging technical expertise and community-driven solutions—deploying drones for ecological assessments and collaborating with organizations like UNDP, WWF, and the International Climate Initiative to drive impactful environmental initiatives.\nSpecializing in Conservation Planning at the Bren School, I’m developing expertise in environmental modeling and data visualization to support restoration interventions that enhance climate resilience.\n\n\nA little bit more..\nBeyond research, I find balance and inspiration through surfing and hiking. Being immersed in nature not only grounds me but also reminds me of the importance of the work I do.\nLiving and working on islands has shown me firsthand how communities depend on these ecosystems for their livelihoods, culture, and protection. These experiences have shaped my passion for coral reef restoration, particularly understanding how reefs are connected and how restoration can build resilience in the face of mounting climate challenges."
  }
]