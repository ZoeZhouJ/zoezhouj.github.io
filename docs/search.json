[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "Phoenix BII Analysis\n\n\n\n\n\n\nZoe Zhou\n\n\n\n\n\n\n\n\n\n\n\n\nThrough the Smoke: Understanding Wildfire Impacts\n\n\n\n\n\n\nZoe Zhou\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zoe Zhou",
    "section": "",
    "text": "Welcome! Join me in navigating the world, one dataset at a time.\n\nEnter here"
  },
  {
    "objectID": "index.html#aspiring-environmental-data-scientist",
    "href": "index.html#aspiring-environmental-data-scientist",
    "title": "Zoe Zhou",
    "section": "",
    "text": "Welcome! Join me in navigating the world, one dataset at a time.\n\nEnter here"
  },
  {
    "objectID": "posts/2025-01-24-wildfire-analysis/index.html",
    "href": "posts/2025-01-24-wildfire-analysis/index.html",
    "title": "Through the Smoke: Understanding Wildfire Impacts",
    "section": "",
    "text": "Discover how data from the Thomas Fire sheds light on wildfire impacts, from air quality degradation to environmental recovery, and its relevance to Los Angeles’ current challenges.\nAuthor: Zoe Zhou\nGitHub Repository with Full Analysis\n Image credits: NASA\n\nAbout\nThe hillsides of Los Angeles are once again shrouded in smoke as wildfires rage, turning familiar landscapes into scenes of devastation. Beyond the flames, the air itself becomes a silent hazard, the impacts of smoke and poor air quality linger, posing significant risks to public health and the environment.\nLooking back at the devastating 2017 Thomas Fire, one of California’s largest wildfires, we gain valuable insights into the aftermath of such events. It consumed 281,893 acres across Santa Barbara and Ventura counties, destroying hundreds of structures and significantly impacting local ecology and regional air quality. This blog revisits those findings and bridges them to the ongoing crisis in Los Angeles. Through this work, we aim to contribute to the growing body of knowledge about wildfire impacts and recovery patterns in California’s coastal regions.\nThe analysis demonstrates the application of geospatial analysis techniques in environmental monitoring, and provides insights into the environmental and public health impacts of large-scale wildfires in California’s changing climate.\n\n\nHighlights\n\nFalse-Color Imaging: Visualized vegetation health and burn scars using Landsat multispectral bands, revealing insights into fire severity and ecological recovery.\nAir Quality Assessment: Quantified the Thomas FIre’s impact on AQI in Santa Barbara County, using time-series data to illustrate pollution trends during and after the fire.\nGeospatial Analysis: Leveraged Python libraries for geospatial processing, including geopandas, xarray, and rasterio.\n\n\n\nDatasets\n\nLandsat Surface Reflectance Data\nSource: Microsoft Planetary Computer - Landsat Collection 2 Level-2 This data contains Red, Green, Blue (RGB), Near-Infrared(NIR), and Shortwave Infrared (SWIR) bands. Pre-processed to remove data outside study area and coarsen the spatial resolution. False color image created by using the short-wave infrared (swir22), near-infrared, and red variables.\nAir Quality Index (AQI) Data\nSource: Environmental Protection Agancy (EPA) - Air Data This data contains daily AQI values for Santa Barbara County from 2017 to 2018.\nThomas Fire perimeter data Source: CalFire The database includes information on fire date, managing agency, cause, acres, and the geospatial boundary of the fire, among other information. This data was pre-processed to select only the Thomas fire boundary geometry.\n\n\n\nSet Up\nWe will use the following libraries and set-up through this analysis\n\n# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os \nimport geopandas as gpd\nimport rioxarray as rioxr\nimport xarray as xr\nimport matplotlib.patches as mpatches \n\n\n# Set option to display all columns\npd.set_option('display.max_columns', None)\n\n\n\nPart 1: Visualizing Burn Scars\nObjective:\nWe will create a false-color image of the Thomas Fire to explore how remote sensing and data visualization aid environmental monitoring. False-color imagery, using infrared bands, highlights vegetation health, burn severity, and fire scars. This helps assess recovery, identify risks, and plan restoration.\n\nImport Data\n\n# Import landsat nc data\nlandsat = rioxr.open_rasterio('data/landsat8-2018-01-26-sb-simplified.nc')\n# Import fire boundary shapefile\nthomas = gpd.read_file('data/thomas-fire-boundary-file')\n\n\n\nPrepare data for mapping\nClean redundant dimension of landsat data\n\n# Remove any length 1 dimension and its coordinates\nlandsat = landsat.squeeze().drop_vars('band')\n\nAfter data wrangling we are ready for mapping. But first we need to ensure coordinate reference systems (CRS) of spatial data are matched.\n\n\n# Match CRS for plotting\nthomas = thomas.to_crs(landsat.rio.crs)\n\n# Test for matching CRS\nassert landsat.rio.crs == thomas.crs\n\nBecause Landsat data is downloaded with a estimated box, it’s going to be larger than the thomas fire boundary. We clip landsat with thomas fire boundary to focus on study area.\n\nthomas_landsat = landsat.rio.clip_box(*thomas.total_bounds)\n\nObtain aspect ratio with height and width to avoid distortion when mapping\n\n# Print height and width of landsat data\nprint('Height:', thomas_landsat.rio.height)\nprint('Width:', thomas_landsat.rio.width)\n\n# Calculate aspect ratio for plotting \naspect_ratio = thomas_landsat.rio.width/thomas_landsat.rio.height\naspect_ratio\n\nHeight: 149\nWidth: 259\n\n\n1.738255033557047\n\n\n\n\nMap the Thomas Fire Scar\n\n# Initialize figure\nfig, ax = plt.subplots(figsize = (8, 6*aspect_ratio))\n\n# Plot landsat map by calling false image bands\n(thomas_landsat[['swir22', 'nir08', 'red']]\n .to_array()\n .plot.imshow(ax=ax,\n              robust=True))\n\n# Overlay thomas fire boundary \nthomas.boundary.plot(ax=ax,\n                    edgecolor=\"blue\",\n                    linewidth=1,\n                    label='Thomas Fire Boundary')\n\n# Add legend\n# Create a legend for the false color bands and boundary\nlegend_swir = mpatches.Patch(color = \"#eb6a4b\", label = 'Shortwave Infrared \\n - Burned Area')\nlegend_nir = mpatches.Patch(color = \"#a1fc81\", label = 'Near Infrared \\n - Vegetation')\nlegend_bound = mpatches.Patch(color = \"blue\", label = 'Thomas Fire Boundary')\n# Clean up map\nax.legend(handles = [legend_swir, legend_nir, legend_bound], loc = 'upper right')\nax.set_title('False Color Map with the Thomas Fire Boundary')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1. False Color Map of the 2017 Thomas Fire\nThis map displays the 2017 Thomas Fire region using false-color imagery derived from Landsat data. The pinkish/salmon colored area within the blue boundary line represents the burn scar from the Thomas Fire. The bright green areas surrounding the burn scar represent healthy, unburned vegetation. Using SWIR (shortwave infrared), NIR (near infrared), and red bands is particularly effective for burn scar analysis because:\n\nSWIR is sensitive to burn scars and can penetrate smoke\nNIR helps distinguish between burned and unburned vegetation\nRed light helps with overall land feature distinction\n\nThis visualization enhances the identification of burn scars, vegetation health, and moisture content.\n\n\n\nPart 2: Analyzing Fire Impact on AQI\nObjective:\nThis part of the analysis shows the dramatic impact of the Thomas Fire on Santa Barbara’s air quality. The study built time series visualization showing clear air quality change during fire period. A 5 day rolling averages is created to smooth daily fluctuations and identify trends.\n\nImport Data\n\n# Read in data\naqi_17 = pd.read_csv('data/daily_aqi_by_county_2017.zip', compression='zip')\naqi_18 = pd.read_csv('data/daily_aqi_by_county_2018.zip', compression='zip')\n\n\n\nPrepare AQI Tables for Analysis\nWe combined AQI data from 2017-2018 to analyze air quality trends during the Thomas Fire period. After merging the datasets, we filtered specifically for Santa Barbara County and removed unnecessary columns to streamline the analysis.\n\n# concatenate tables\naqi = pd.concat([aqi_17,aqi_18])\n\n# Clean column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_'))\n\n# Select data from SB county and store as variable\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara'] \n\n# Drop unnecessary columns in SB\naqi_sb = aqi_sb.drop(columns=['state_name','county_name','state_code','county_code'])\n\n# Verify operations \naqi_sb.head(3)\n\n\n\n\n\n\n\n\ndate\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\n\n\n\n\n28648\n2017-01-01\n39\nGood\nOzone\n06-083-4003\n12\n\n\n28649\n2017-01-02\n39\nGood\nPM2.5\n06-083-2011\n11\n\n\n28650\n2017-01-03\n71\nModerate\nPM10\n06-083-4003\n12\n\n\n\n\n\n\n\n\n\nTime Series Processing\nTo address daily fluctuations and provide a clearer trend, we will implement a 5-day rolling average. This method smooths the data by averaging values over a sliding 5-day window, ensuring that short-term variations are minimized while preserving the overall pattern in the dataset.\n\n# Convert dates to datetime date type\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n                     \n# Assign date column as index\naqi_sb = aqi_sb.set_index('date')\n\n# Define a new column in aqi_sb\naqi_sb['five_day_average'] = aqi_sb['aqi'].rolling('5D').mean()\n\n\n\nVisualization\nWe can create a visualization that displays daily AQI values alongside the smoothed 5-day rolling average, using matplotlib. This plot provides a clear view of short-term fluctuations and overall trends.\n\n# Create a plot\n\nax = (aqi_sb.drop(columns='number_of_sites_reporting') # Drop unnecessary column\n        .plot(title='Daily AQI and 5-day average AQI in Santa Barbara from 2017 to 2018',\n              ylabel='Air Quality Index',\n              color=['salmon','blue'] \n)\n)                                     \n# Show the date of the Thomas fire\nplt.axvline(x = '2017-12-04', \n            color = 'red', \n            linestyle = 'dashed', \n            label = \"Thomas Fire\")   \nplt.legend()                  \n\n\n\n\n\n\n\n\nFigure 2. Daily AQI and 5-day AQI averages in Santa Barbara County\nDuring the peak fire period in December 2017, AQI values spiked significantly above normal levels. The 5-day rolling average helps smooth out daily fluctuations while still highlighting the severe deterioration in air quality during the fire. Outside of the fire period, Santa Barbara generally maintained good air quality with AQI values typically below 100. This makes the fire’s impact even more striking, as 5-day AQI values rose well above 200 during the incident."
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html",
    "href": "posts/2025-02-03-urban-biodiversity/index.html",
    "title": "Phoenix BII Analysis",
    "section": "",
    "text": "Author: Zoe Zhou\nLink to github repo\nCourse Website: EDS 220"
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html#about",
    "href": "posts/2025-02-03-urban-biodiversity/index.html#about",
    "title": "Phoenix BII Analysis",
    "section": "About",
    "text": "About\nPurpose: This project analyzes changes in the Biodiversity Intactness Index (BII) in Phoenix, Arizona (Maricopa County) between 2017 and 2020. The analysis aims to understand the impact of urban expansion on local biodiversity, as Phoenix has experienced significant urban development in recent decades.\nHighlights: - Data Exploration: Accessing and extracting geospatial data through the pystac_client API,focusing on specific collections and spatial extents. Implementing raster data processing using rioxarray.\n\nTemporal BII Analysis: Analyzing changes in the Biodiversity Intactness Index (BII) across Phoenix from 2017 to 2020, with particular emphasis on areas maintaining high biodiversity values (BII ≥ 0.75). Quantifying percentage changes to measure the impact of urban development on local ecosystems.\nSpatial Visualization: Developing comprehensive visualizations using multiple data layers to illustrate biodiversity changes. Combining vector and raster datasets to create informative maps that highlight areas of significant BII loss.\n\nAbout the data:\nThis study utilizes two primary datasets to analyze biodiversity changes in Phoenix. The Biodiversity Intactness Index (BII) data is sourced from Microsoft Planetary Computer’s STAC catalog’s io-biodiversity collection, specifically focusing on temporal changes between 2017 and 2020. The analysis area is defined by a bounding box with coordinates [-112.826843, 32.974108, -111.184387, 33.863574] encompassing the Phoenix metropolitan region. The study area boundaries are defined using the Phoenix subdivision shapefile, obtained from the 2020 TIGER/Line® Shapefiles published by the US Census Bureau, which provides detailed county subdivision boundaries for Arizona.\nSource:\nMicrosoft Open Source, Matt McFarland, Rob Emanuele, Dan Morris, & Tom Augspurger. (2022). microsoft/PlanetaryComputer: October 2022 (2022.10.28). Zenodo. https://doi.org/10.5281/zenodo.7261897 Accessed: 2024-12-02\n2020 TIGER/Line Shapefiles (machinereadable data files) / prepared by the U.S. Census Bureau, 2020 https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2020&layergroup=County+Subdivisions Accessed: 2024-12-02\n\nSet Up\nWe will use the following libraries and set-up through this analysis\n\n# Import libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt # To plot the final figure\nimport matplotlib.pyplot as mlines # To add legend to final figure\nimport geopandas as gpd # To work with shapefiles\nimport rioxarray as rioxr # To work with rasters\nimport contextily as ctx # To add a basemap\n\nfrom pystac_client import Client # To access STAC catalogs\n\nimport planetary_computer # To sign items from the MPC STAC catalog\n\nfrom IPython.display import Image # To nicely display images\n\n# Set option to display all columns\npd.set_option('display.max_columns', None)\n\n\n\nData Exploration\n\nBefore retriveing any data, update .gitignore with the entire data directory for best version control efficiency.\nDownload and import TIGER county subdivisons shapefile for Arizona in 2020.\nAdd a base map from the contextily package\n\n\n# Load boundary data\narizona = gpd.read_file(os.path.join('./data/','tl_2020_04_cousub.shp'))\narizona.head()\n\n# Filter for Phoenix\nphoenix = arizona[arizona['NAME'] == 'Phoenix'] \nphoenix.head()\n\n# Get general information about data\nphoenix.plot()\nphoenix.crs\n\n&lt;Geographic 2D CRS: EPSG:4269&gt;\nName: NAD83\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: North America - onshore and offshore: Canada - Alberta; British Columbia; Manitoba; New Brunswick; Newfoundland and Labrador; Northwest Territories; Nova Scotia; Nunavut; Ontario; Prince Edward Island; Quebec; Saskatchewan; Yukon. Puerto Rico. United States (USA) - Alabama; Alaska; Arizona; Arkansas; California; Colorado; Connecticut; Delaware; Florida; Georgia; Hawaii; Idaho; Illinois; Indiana; Iowa; Kansas; Kentucky; Louisiana; Maine; Maryland; Massachusetts; Michigan; Minnesota; Mississippi; Missouri; Montana; Nebraska; Nevada; New Hampshire; New Jersey; New Mexico; New York; North Carolina; North Dakota; Ohio; Oklahoma; Oregon; Pennsylvania; Rhode Island; South Carolina; South Dakota; Tennessee; Texas; Utah; Vermont; Virginia; Washington; West Virginia; Wisconsin; Wyoming. US Virgin Islands. British Virgin Islands.\n- bounds: (167.65, 14.92, -40.73, 86.45)\nDatum: North American Datum 1983\n- Ellipsoid: GRS 1980\n- Prime Meridian: Greenwich\n\n\n\n\n\n\n\n\n\nDate Summary: The 2020 TIGER/Line Arizona County Subdivisions dataset provides detailed administrative boundary information for the 61 county subdivisions in Arizona. It is available as a GeoDataFrame containing multiple attributes including geographic identifiers (GEOID), names, legal/statistical area descriptions, and precise boundary geometries. The dataset uses the NAD83 (EPSG:4269) coordinate system and is updated annually as part of the U.S. Census Bureau’s TIGER/Line program.\n\n# Plot Phoenix area together with a base map\n\n# Initialize figure\nfig, ax = plt.subplots(figsize =(10, 10))\n\n# Plot city boundary\nphoenix.boundary.plot(ax=ax,\n                     color='blue')\n# Add base map\nctx.add_basemap(ax=ax, \n                # source=ctx.providers.CartoDB.Voyager, \n                crs=phoenix.crs)\n\n# Clean map\nax.set_title('Map of Phoenix')\nax.axis('off')\nax.legend(phoenix['NAME'])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Save file as GeoJSON for reproducibility\nphoenix.to_file('data_clean/phoenix-boundary-file', driver='GeoJSON')\n\nNow that we have Phoenix boundary mapped, we can move on to the Biodiversity Index dataset.\n\nAccess BII data from MPC\n\nWorkflow: - Define bounding box and time range for search - Open MPC catalog - Search MPC catalog for io_biodiversity collection with bounding box and time_range - Retrive search items - Select unique search item - Examine item.assets keys and title - Display pre-rendered image - Save data\n\n# Define study extent and time range\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]\ntime_range = \"2017-01-01/2020-01-01\"\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n# Search for collection \nsearch = catalog.search(\n    collections=['io-biodiversity'],\n    bbox=bbox,\n    datetime=time_range)\nsearch\n\n# Retrieve items\nitems = search.item_collection()\nitems\n# Determine number of items in search\nprint(f'There are {len(items)} items in the search.')\n\nThere are 4 items in the search.\n\n\n\nitem=items[0]\n# Check assets in item \nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\ndata -- Biodiversity Intactness\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\n\n# Plot rendered preview\nImage(url=item.assets['rendered_preview'].href, width=500)\n\n\n\n\nIt seems that our biodiversity data is larger than phoenix. Let’s access the BII data and clip to study extent"
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html#clip-raster-to-geometry",
    "href": "posts/2025-02-03-urban-biodiversity/index.html#clip-raster-to-geometry",
    "title": "Phoenix BII Analysis",
    "section": "Clip raster to geometry",
    "text": "Clip raster to geometry\n\n# Explore data \nprint(type(items))\nprint(len(items))\nprint(items[0].assets['data'].href)\n\n&lt;class 'pystac.item_collection.ItemCollection'&gt;\n4\nhttps://pcdata01euw.blob.core.windows.net/impact/bii-v1/bii_2020/bii_2020_34.74464974521749_-115.38597824385106_cog.tif?st=2024-12-08T00%3A17%3A42Z&se=2024-12-09T01%3A02%3A42Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2024-12-08T03%3A52%3A20Z&ske=2024-12-15T03%3A52%3A20Z&sks=b&skv=2024-05-04&sig=aPPNFKqsw8IBhVdRMBurGkpa2RhJ7mc6qWmptB3E37s%3D\n\n\nThere’s only 1 dimension for band so it’s efficient to drop it using the squeeze() and .drop_vars()\n\n# Select and process 2020 and 2017 data \nfor idx in [0, 3]:\n    # Load data\n    bii = rioxr.open_rasterio(items[idx].assets['data'].href)\n    # Drop band dimension \n    bii = bii.squeeze().drop_vars('band')\n    \n    # Match CRS and clip\n    phoenix_match = phoenix.to_crs(bii.rio.crs)\n    assert phoenix_match.crs == bii.rio.crs\n    \n    # Clip the raster to phoenix geometry\n    year = '2020' if idx == 0 else '2017'\n    globals()[f'bii_{year}_phoenix'] = (bii.rio.clip_box(*phoenix_match.total_bounds)\n                                    .rio.clip(phoenix_match.geometry))\n\n\n# Check clipped data\nprint(bii_2020_phoenix)\nbii_2020_phoenix.plot()\n\n&lt;xarray.DataArray (y: 583, x: 990)&gt; Size: 2MB\narray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\nCoordinates:\n  * x            (x) float64 8kB -112.5 -112.5 -112.5 ... -111.6 -111.6 -111.6\n  * y            (y) float64 5kB 33.81 33.81 33.81 33.81 ... 33.29 33.29 33.29\n    spatial_ref  int64 8B 0\nAttributes:\n    AREA_OR_POINT:  Area\n    scale_factor:   1.0\n    add_offset:     0.0"
  },
  {
    "objectID": "posts/2025-02-03-urban-biodiversity/index.html#calculate-percent-area-with-bii-0.75",
    "href": "posts/2025-02-03-urban-biodiversity/index.html#calculate-percent-area-with-bii-0.75",
    "title": "Phoenix BII Analysis",
    "section": "Calculate percent area with BII >0.75",
    "text": "Calculate percent area with BII &gt;0.75\nTo calculate percent area, we need total pixel counts of phoenix and then pixel counts with BII &gt;= 0.75.\n\n# Count total Phoenix pixels\ntotal_counts = bii_2020_phoenix.count().item()\nprint(f\"There are {total_counts} pixels in Phoenix\")\n# Select BII &gt;= 0.75\nover75_2020 = (bii_2020_phoenix &gt;= 0.75).astype(int)\nover75_2017 = (bii_2017_phoenix &gt;= 0.75).astype(int)\n\nThere are 338699 pixels in Phoenix\n\n\n\n# Count threshold pixels in 2020 \nvalue, counts = np.unique(over75_2020, return_counts=True)\nassert len(value) == len(counts)\n# Initialize dictionary with column's data\ndic = {'code': value,\n       'counts': counts}\n# Create a data frame \npix_counts_20 = pd.DataFrame(dic)\npix_counts_20\n# Report findings\nprint(f\"There are {pix_counts_20.iloc[1,1]} pixels with BII &gt;= 0.75 in 2020\")\n\nThere are 21986 pixels with BII &gt;= 0.75 in 2020\n\n\nWhile it’s easy to run the same code for 2017, it’s better to write a for loop to maintain best coding practice.\n\n# Count pixels with condition\nyears = {'2020': over75_2020, '2017': over75_2017}  # map years to their data\n\nfor year, data in years.items():\n    # Count pixels for True/False\n    value, counts = np.unique(data, return_counts=True)\n    assert len(value) == len(counts)\n    \n    # Create dataframe\n    dic = {'code': value, 'counts': counts}\n    globals()[f'pix_counts_{year[-2:]}'] = pd.DataFrame(dic)  # creates pix_counts_20 and pix_counts_17\n    \n    # Save counts as variable\n\n    globals()[f'counts_75_{year}'] = counts[1]\n        \n    # Report findings\n    print(f\"There are {counts[1]} pixels with BII &gt;= 0.75 in {year}\")\n\nThere are 21986 pixels with BII &gt;= 0.75 in 2020\nThere are 24133 pixels with BII &gt;= 0.75 in 2017\n\n\n\n# Plot the data to check extent\nover75_2017.plot()\n\n\n\n\n\n\n\n\nNow that we have pixel counts of both total cells in Phoenix and BII &gt; 75% cells, we can calculate the percent area with a simple division.\n\n# Write a \"for loop\" to run calculation for both years\nratio_2017 = round((counts_75_2017/total_counts)*100, 2)\nratio_2017\n\n7.13\n\n\n\nfor year in years:\n    # Calculate ratio\n    globals()[f'ratio_{year}'] = (globals()[f'counts_75_{year}']/total_counts) * 100\n    # Print result\n    print(f\"In {year}, {globals()[f'ratio_{year}']:.2f}% of pixels have BII &gt;= 0.75\")\n\nIn 2020, 6.49% of pixels have BII &gt;= 0.75\nIn 2017, 7.13% of pixels have BII &gt;= 0.75\n\n\n\n# Obtain BII loss between 2017 to 2020\nloss = over75_2017 - over75_2020\nloss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (y: 583, x: 990)&gt; Size: 5MB\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\nCoordinates:\n  * x            (x) float64 8kB -112.5 -112.5 -112.5 ... -111.6 -111.6 -111.6\n  * y            (y) float64 5kB 33.81 33.81 33.81 33.81 ... 33.29 33.29 33.29\n    spatial_ref  int64 8B 0xarray.DataArrayy: 583x: 9900 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])Coordinates: (3)x(x)float64-112.5 -112.5 ... -111.6 -111.6axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-112.469598, -112.468699, -112.467801, ..., -111.58296 , -111.582062,\n       -111.581164])y(y)float6433.81 33.81 33.81 ... 33.29 33.29axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([33.813546, 33.812648, 33.811749, ..., 33.292523, 33.291625, 33.290726])spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-112.47004683159909 0.0008983152841195194 0.0 33.81399511086966 0.0 -0.0008983152841195182array(0)Indexes: (2)xPandasIndexPandasIndex(Index([-112.46959767395703, -112.46869935867291, -112.46780104338879,\n       -112.46690272810467, -112.46600441282054, -112.46510609753642,\n        -112.4642077822523, -112.46330946696818, -112.46241115168407,\n       -112.46151283639995,\n       ...\n        -111.5892486955199, -111.58835038023577, -111.58745206495165,\n       -111.58655374966753, -111.58565543438341,  -111.5847571190993,\n       -111.58385880381518, -111.58296048853106, -111.58206217324694,\n       -111.58116385796282],\n      dtype='float64', name='x', length=990))yPandasIndexPandasIndex(Index([  33.8135459532276, 33.812647637943485,  33.81174932265937,\n        33.81085100737524,  33.80995269209112, 33.809054376807005,\n        33.80815606152289,  33.80725774623877,  33.80635943095465,\n       33.805461115670525,\n       ...\n       33.298811295427114, 33.297912980142996,  33.29701466485888,\n        33.29611634957476,  33.29521803429064,  33.29431971900652,\n         33.2934214037224,  33.29252308843828,  33.29162477315416,\n        33.29072645787004],\n      dtype='float64', name='y', length=583))Attributes: (0)\n\n\nValue in loss variable represents change of BII between the years. 1 indicates BII loss, and -1 indicates BII gain, 0 means no change.\n\n# Select xarray cells with value of 1 \nloss = loss.where(loss==1)\nloss\nloss.plot()\n\n\n\n\n\n\n\n\n\nVisualize biodiversity loss\n\n# Define aspect ratio with height and width\naspect = bii_2020_phoenix.rio.width/bii_2020_phoenix.rio.height\n\n# Initialize figure\nfig, ax = plt.subplots(figsize=(10, 4*aspect))\n\n# Plot the BII raster in 2020\nbii_2020_phoenix.plot(ax=ax,\n                     cbar_kwargs={\n                    \"orientation\": \"horizontal\",\n                    \"label\": \"BII for 2020\"}\n                     )\n\n# Plot the loss layer\nloss.plot(ax=ax,\n         cmap=\"inferno\",\n         add_colorbar=False)\n\n# Plot city boundary\nphoenix.boundary.plot(ax=ax,\n                     color='blue')\n\n# Set legend for change raster\nred_patch = mlines.Line2D([], [], color = \"red\", \n                          label = \"Biodiversity area loss\", \n                          linewidth = 4)\n\nax.legend(handles = [red_patch],\n          bbox_to_anchor=(0, 0, 0.75, 0),\n         fontsize = 8)\n\n# Set title\nax.set_title(\"Biodiversity Intactness Index (BII) \\nPhoenix Subdivision\")\n\n# Turn axis off\nax.axis(\"off\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThis figure shows the Biodiversity Intactness Index (BII) for the Phoenix Subdivision in 2020. The BII values are displayed using a color gradient scale ranging from 0.1 to 0.8. The area is outlined in blue, showing the subdivision boundaries. Quantitative analysis reveals a decline in high-biodiversity areas between 2017 and 2020. In 2017, 7.13% of the area had high biodiversity intactness (BII ≥ 0.75), which decreased to 6.49% by 2020. This decline is visually represented by the red areas marking “Biodiversity area loss,” which appear in two main locations: a larger area in the northeastern section of the subdivision and another smaller cluster in the southern portion."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi there! I’m Zoe Zhou, my Chinese name 周佳瑞 is pronounced as “Jo jar-ray”. I’m a graduate student at the Bren School of Environmental Science & Management at UCSB.\nThis site is a reflection of my passions. Here, you’ll find:\n\nProjects where I unravel patterns and tell stories hidden in data.\nA Photography Gallery filled with snapshots of natural beauty and candid moments.\nInsights into my journey, aspirations, and maybe even a few experiments (both in data and life).\n\nI’m on a mission to merge the power of data with the beauty of nature, finding stories in numbers and moments in the wild.\nWhether you’re here for inspiration, collaboration, or simply to wander, I’m excited to have you along for the ride.\n\n\nBackground\nI graduated from the University of Washington in 2016 with Bachelor of Science degrees in Economics and Earth Science, a combination that shaped my approach to tackling environmental inequities as a sustainable development project officer.\nOver the years, I’ve led coastal conservation projects on the Island of Hainan, China, where I combined technical expertise with community-driven solutions. From deploying drones for ecological assessments to navigating grant processes with organizations like UNDP, WWF, and the International Climate Initiative, I’ve honed the ability to balance technical proficiency with local insights. My work has consistently centered on integrating sustainable practices to address ecological and community needs.\nCurrently, I’m pursuing a specialization in Conservation Planning at the Bren School of Environmental Science & Management. I’m focused on sharpening my skills in ecosystem services modeling and restoration planning to design strategies that promote sustainable development and help communities build resilience against climate challenges.\n\n\nResearch\nLiving and working on islands, including Hainan, China, has shown me firsthand how communities depend on these ecosystems for their livelihoods, culture, and protection. These experiences have shaped my passion for coral reef restoration, particularly understanding how reefs are connected and how restoration can build resilience in the face of mounting climate challenges.\nMy research focuses on coral connectivity modeling, where I explore how coral larvae travel across ocean currents to settle and grow. Using oceanographic data and larval dispersal models, I work to map the invisible highways that connect coral populations. This knowledge is essential for identifying priority areas for restoration—places where efforts will have the greatest impact not just locally, but across entire reef systems. By understanding these connections, we can better design networks of restored reefs that are more resilient and self-sustaining over time.\n\n\nFor Fun\nOutside of my research, I find balance and inspiration through surfing at sunrise or sunset and hiking in the mountains. Being immersed in nature, whether on the waves or a trail, reminds me why I’m passionate about protecting these incredible ecosystems."
  }
]